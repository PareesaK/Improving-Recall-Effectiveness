{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8b2dbfbe-4e40-454f-8dda-1bac171eb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bd1b8ff-e2c8-47ef-9970-ca4aeafe927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba081130-9374-40cd-9baa-1fb66e86dfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Dataset Information:\n",
      "Shape: (76065, 332)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_sin</th>\n",
       "      <th>Month_cos</th>\n",
       "      <th>Day_sin</th>\n",
       "      <th>Day_cos</th>\n",
       "      <th>DayOfWeek_sin</th>\n",
       "      <th>DayOfWeek_cos</th>\n",
       "      <th>Years_Since_First</th>\n",
       "      <th>Is_US</th>\n",
       "      <th>ProductClassification_Class II</th>\n",
       "      <th>ProductClassification_Class III</th>\n",
       "      <th>...</th>\n",
       "      <th>text_svd_293</th>\n",
       "      <th>text_svd_294</th>\n",
       "      <th>text_svd_295</th>\n",
       "      <th>text_svd_296</th>\n",
       "      <th>text_svd_297</th>\n",
       "      <th>text_svd_298</th>\n",
       "      <th>text_svd_299</th>\n",
       "      <th>Product Classification</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>Event Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.937752</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>-0.015965</td>\n",
       "      <td>-0.016958</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>-0.017736</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>Class II</td>\n",
       "      <td>supplier agfa system noted potential steel sup...</td>\n",
       "      <td>Class II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.897805</td>\n",
       "      <td>-0.440394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>-0.003569</td>\n",
       "      <td>-0.009412</td>\n",
       "      <td>-0.003837</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>Class II</td>\n",
       "      <td>blood collected donor whose suitability donate...</td>\n",
       "      <td>Class II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>-0.994869</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007428</td>\n",
       "      <td>-0.007476</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>0.044938</td>\n",
       "      <td>0.019889</td>\n",
       "      <td>Class II</td>\n",
       "      <td>lack assurance sterility tri mix injectable ml...</td>\n",
       "      <td>Class II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.299363</td>\n",
       "      <td>-0.954139</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>-0.006782</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>-0.003592</td>\n",
       "      <td>-0.022891</td>\n",
       "      <td>Class II</td>\n",
       "      <td>received several complaints head deck actuator...</td>\n",
       "      <td>Class II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>-0.029533</td>\n",
       "      <td>0.008793</td>\n",
       "      <td>0.033197</td>\n",
       "      <td>-0.025611</td>\n",
       "      <td>0.022909</td>\n",
       "      <td>-0.014812</td>\n",
       "      <td>Class II</td>\n",
       "      <td>sensors reported fluid inside posterior latera...</td>\n",
       "      <td>Class II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month_sin     Month_cos   Day_sin   Day_cos  DayOfWeek_sin  DayOfWeek_cos  \\\n",
       "0  -1.000000 -1.836970e-16 -0.937752  0.347305       0.781831       0.623490   \n",
       "1   0.866025  5.000000e-01  0.897805 -0.440394       0.000000       1.000000   \n",
       "2  -1.000000 -1.836970e-16  0.101168 -0.994869       0.433884      -0.900969   \n",
       "3  -0.866025  5.000000e-01  0.299363 -0.954139       0.781831       0.623490   \n",
       "4  -0.866025  5.000000e-01  0.848644  0.528964      -0.433884      -0.900969   \n",
       "\n",
       "   Years_Since_First  Is_US  ProductClassification_Class II  \\\n",
       "0                  6      0                             1.0   \n",
       "1                  8      1                             1.0   \n",
       "2                 10      1                             1.0   \n",
       "3                  2      1                             1.0   \n",
       "4                  6      1                             1.0   \n",
       "\n",
       "   ProductClassification_Class III  ...  text_svd_293  text_svd_294  \\\n",
       "0                              0.0  ...      0.021836     -0.015965   \n",
       "1                              0.0  ...      0.003260     -0.003569   \n",
       "2                              0.0  ...     -0.007428     -0.007476   \n",
       "3                              0.0  ...      0.005633      0.012897   \n",
       "4                              0.0  ...      0.013164     -0.029533   \n",
       "\n",
       "   text_svd_295  text_svd_296  text_svd_297  text_svd_298  text_svd_299  \\\n",
       "0     -0.016958      0.004899      0.018882     -0.017736      0.034006   \n",
       "1     -0.009412     -0.003837      0.012086      0.005998     -0.004990   \n",
       "2     -0.002405      0.020428     -0.023333      0.044938      0.019889   \n",
       "3     -0.006782     -0.001761      0.028885     -0.003592     -0.022891   \n",
       "4      0.008793      0.033197     -0.025611      0.022909     -0.014812   \n",
       "\n",
       "   Product Classification                                      combined_text  \\\n",
       "0                Class II  supplier agfa system noted potential steel sup...   \n",
       "1                Class II  blood collected donor whose suitability donate...   \n",
       "2                Class II  lack assurance sterility tri mix injectable ml...   \n",
       "3                Class II  received several complaints head deck actuator...   \n",
       "4                Class II  sensors reported fluid inside posterior latera...   \n",
       "\n",
       "   Event Classification  \n",
       "0              Class II  \n",
       "1              Class II  \n",
       "2              Class II  \n",
       "3              Class II  \n",
       "4              Class II  \n",
       "\n",
       "[5 rows x 332 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed dataset\n",
    "processed_file_path = '/Users/parisakamizi/Downloads/datasets/train_hybrid.csv'\n",
    "train_df = pd.read_csv(processed_file_path)\n",
    "\n",
    "print(\"\\nProcessed Dataset Information:\")\n",
    "print(f\"Shape: {train_df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "936afb5b-06ba-4b9c-9643-fe9bc8760dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = train_df.drop('Event Classification', axis=1)\n",
    "y = train_df['Event Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "23fd324f-9ba7-47db-bf48-e09b0130111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode features and target\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "if categorical_cols.any():\n",
    "    X[categorical_cols] = OrdinalEncoder().fit_transform(X[categorical_cols])\n",
    "X = X.astype(int)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c722720b-1556-4598-afd3-30601a3482e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Evaluating with 3-fold CV\n",
      "========================================\n",
      "\n",
      "Fold 1/3\n",
      "Accuracy: 0.9916\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      5363\n",
      "    Class II       1.00      0.99      0.99     17953\n",
      "   Class III       0.95      0.98      0.97      2039\n",
      "\n",
      "    accuracy                           0.99     25355\n",
      "   macro avg       0.98      0.99      0.98     25355\n",
      "weighted avg       0.99      0.99      0.99     25355\n",
      "\n",
      "\n",
      "Fold 2/3\n",
      "Accuracy: 0.9925\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      5363\n",
      "    Class II       1.00      0.99      0.99     17953\n",
      "   Class III       0.95      0.98      0.97      2039\n",
      "\n",
      "    accuracy                           0.99     25355\n",
      "   macro avg       0.98      0.99      0.99     25355\n",
      "weighted avg       0.99      0.99      0.99     25355\n",
      "\n",
      "\n",
      "Fold 3/3\n",
      "Accuracy: 0.9918\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      5363\n",
      "    Class II       1.00      0.99      0.99     17953\n",
      "   Class III       0.95      0.99      0.97      2039\n",
      "\n",
      "    accuracy                           0.99     25355\n",
      "   macro avg       0.98      0.99      0.99     25355\n",
      "weighted avg       0.99      0.99      0.99     25355\n",
      "\n",
      "\n",
      "==============================\n",
      "3-Fold CV Summary:\n",
      "Mean Accuracy: 0.9920\n",
      "Std Dev: 0.0004\n",
      "Min Accuracy: 0.9916\n",
      "Max Accuracy: 0.9925\n",
      "==============================\n",
      "\n",
      "========================================\n",
      "Evaluating with 5-fold CV\n",
      "========================================\n",
      "\n",
      "Fold 1/5\n",
      "Accuracy: 0.9926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      3218\n",
      "    Class II       1.00      0.99      1.00     10772\n",
      "   Class III       0.95      0.98      0.97      1223\n",
      "\n",
      "    accuracy                           0.99     15213\n",
      "   macro avg       0.98      0.99      0.99     15213\n",
      "weighted avg       0.99      0.99      0.99     15213\n",
      "\n",
      "\n",
      "Fold 2/5\n",
      "Accuracy: 0.9915\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      3218\n",
      "    Class II       1.00      0.99      0.99     10772\n",
      "   Class III       0.95      0.99      0.97      1223\n",
      "\n",
      "    accuracy                           0.99     15213\n",
      "   macro avg       0.98      0.99      0.98     15213\n",
      "weighted avg       0.99      0.99      0.99     15213\n",
      "\n",
      "\n",
      "Fold 3/5\n",
      "Accuracy: 0.9930\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      1.00      3218\n",
      "    Class II       1.00      0.99      1.00     10772\n",
      "   Class III       0.96      0.98      0.97      1223\n",
      "\n",
      "    accuracy                           0.99     15213\n",
      "   macro avg       0.98      0.99      0.99     15213\n",
      "weighted avg       0.99      0.99      0.99     15213\n",
      "\n",
      "\n",
      "Fold 4/5\n",
      "Accuracy: 0.9910\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      3217\n",
      "    Class II       1.00      0.99      0.99     10772\n",
      "   Class III       0.94      0.99      0.96      1224\n",
      "\n",
      "    accuracy                           0.99     15213\n",
      "   macro avg       0.98      0.99      0.98     15213\n",
      "weighted avg       0.99      0.99      0.99     15213\n",
      "\n",
      "\n",
      "Fold 5/5\n",
      "Accuracy: 0.9926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      3218\n",
      "    Class II       1.00      0.99      0.99     10771\n",
      "   Class III       0.96      0.98      0.97      1224\n",
      "\n",
      "    accuracy                           0.99     15213\n",
      "   macro avg       0.98      0.99      0.99     15213\n",
      "weighted avg       0.99      0.99      0.99     15213\n",
      "\n",
      "\n",
      "==============================\n",
      "5-Fold CV Summary:\n",
      "Mean Accuracy: 0.9921\n",
      "Std Dev: 0.0008\n",
      "Min Accuracy: 0.9910\n",
      "Max Accuracy: 0.9930\n",
      "==============================\n",
      "\n",
      "========================================\n",
      "Evaluating with 10-fold CV\n",
      "========================================\n",
      "\n",
      "Fold 1/10\n",
      "Accuracy: 0.9928\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      1.00      0.99      1609\n",
      "    Class II       1.00      0.99      1.00      5386\n",
      "   Class III       0.95      0.99      0.97       612\n",
      "\n",
      "    accuracy                           0.99      7607\n",
      "   macro avg       0.98      0.99      0.99      7607\n",
      "weighted avg       0.99      0.99      0.99      7607\n",
      "\n",
      "\n",
      "Fold 2/10\n",
      "Accuracy: 0.9926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      1609\n",
      "    Class II       1.00      0.99      0.99      5386\n",
      "   Class III       0.96      0.98      0.97       612\n",
      "\n",
      "    accuracy                           0.99      7607\n",
      "   macro avg       0.98      0.99      0.99      7607\n",
      "weighted avg       0.99      0.99      0.99      7607\n",
      "\n",
      "\n",
      "Fold 3/10\n",
      "Accuracy: 0.9917\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      1609\n",
      "    Class II       1.00      0.99      0.99      5386\n",
      "   Class III       0.95      0.98      0.97       612\n",
      "\n",
      "    accuracy                           0.99      7607\n",
      "   macro avg       0.98      0.99      0.98      7607\n",
      "weighted avg       0.99      0.99      0.99      7607\n",
      "\n",
      "\n",
      "Fold 4/10\n",
      "Accuracy: 0.9913\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      1609\n",
      "    Class II       1.00      0.99      0.99      5386\n",
      "   Class III       0.94      0.98      0.96       612\n",
      "\n",
      "    accuracy                           0.99      7607\n",
      "   macro avg       0.98      0.99      0.98      7607\n",
      "weighted avg       0.99      0.99      0.99      7607\n",
      "\n",
      "\n",
      "Fold 5/10\n",
      "Accuracy: 0.9933\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      1609\n",
      "    Class II       1.00      0.99      1.00      5386\n",
      "   Class III       0.96      0.98      0.97       612\n",
      "\n",
      "    accuracy                           0.99      7607\n",
      "   macro avg       0.98      0.99      0.99      7607\n",
      "weighted avg       0.99      0.99      0.99      7607\n",
      "\n",
      "\n",
      "Fold 6/10\n",
      "Accuracy: 0.9926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      1609\n",
      "    Class II       0.99      0.99      0.99      5386\n",
      "   Class III       0.96      0.98      0.97       611\n",
      "\n",
      "    accuracy                           0.99      7606\n",
      "   macro avg       0.98      0.99      0.99      7606\n",
      "weighted avg       0.99      0.99      0.99      7606\n",
      "\n",
      "\n",
      "Fold 7/10\n",
      "Accuracy: 0.9907\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      1609\n",
      "    Class II       1.00      0.99      0.99      5386\n",
      "   Class III       0.94      0.98      0.96       611\n",
      "\n",
      "    accuracy                           0.99      7606\n",
      "   macro avg       0.98      0.99      0.98      7606\n",
      "weighted avg       0.99      0.99      0.99      7606\n",
      "\n",
      "\n",
      "Fold 8/10\n",
      "Accuracy: 0.9921\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      1.00      0.99      1609\n",
      "    Class II       1.00      0.99      0.99      5386\n",
      "   Class III       0.95      0.99      0.97       611\n",
      "\n",
      "    accuracy                           0.99      7606\n",
      "   macro avg       0.98      0.99      0.98      7606\n",
      "weighted avg       0.99      0.99      0.99      7606\n",
      "\n",
      "\n",
      "Fold 9/10\n",
      "Accuracy: 0.9922\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       0.99      0.99      0.99      1608\n",
      "    Class II       1.00      0.99      0.99      5386\n",
      "   Class III       0.96      0.98      0.97       612\n",
      "\n",
      "    accuracy                           0.99      7606\n",
      "   macro avg       0.98      0.99      0.99      7606\n",
      "weighted avg       0.99      0.99      0.99      7606\n",
      "\n",
      "\n",
      "Fold 10/10\n",
      "Accuracy: 0.9932\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      1609\n",
      "    Class II       1.00      0.99      1.00      5385\n",
      "   Class III       0.96      0.99      0.97       612\n",
      "\n",
      "    accuracy                           0.99      7606\n",
      "   macro avg       0.98      0.99      0.99      7606\n",
      "weighted avg       0.99      0.99      0.99      7606\n",
      "\n",
      "\n",
      "==============================\n",
      "10-Fold CV Summary:\n",
      "Mean Accuracy: 0.9923\n",
      "Std Dev: 0.0008\n",
      "Min Accuracy: 0.9907\n",
      "Max Accuracy: 0.9933\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Define fold configurations to test\n",
    "fold_configs = [3, 5, 10]  \n",
    "\n",
    "# xperiment with different fold counts\n",
    "for n_folds in fold_configs:\n",
    "    print(f\"\\n{'='*40}\\nEvaluating with {n_folds}-fold CV\\n{'='*40}\")\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    fold_reports = []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "        print(f\"\\nFold {fold+1}/{n_folds}\")\n",
    "        \n",
    "        # Split and resample\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y_encoded[train_idx], y_encoded[valid_idx]\n",
    "        \n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        y_pred = model.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        report = classification_report(y_valid, y_pred, target_names=le.classes_)\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_reports.append(report)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "    \n",
    "    # Summary for this fold configuration\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"{n_folds}-Fold CV Summary:\")\n",
    "    print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
    "    print(f\"Std Dev: {np.std(fold_accuracies):.4f}\")\n",
    "    print(f\"Min Accuracy: {np.min(fold_accuracies):.4f}\")\n",
    "    print(f\"Max Accuracy: {np.max(fold_accuracies):.4f}\")\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c652a474-d4d0-49a7-b92c-d4e9f83eeaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n",
      "Selected Features: 18\n"
     ]
    }
   ],
   "source": [
    "# For each fold after applying SMOTE\n",
    "for train_idx, valid_idx in skf.split(X, y_encoded):\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y_encoded[train_idx], y_encoded[valid_idx]\n",
    "\n",
    "    # Apply SMOTE on training portion\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Initialize RandomForestClassifier for feature selection\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Select features based on model's importance\n",
    "    selector = SelectFromModel(rf, threshold=\"mean\", max_features=20, importance_getter=\"auto\")\n",
    "    X_train_selected = selector.transform(X_train_smote)\n",
    "    X_valid_selected = selector.transform(X_valid_fold)\n",
    "    \n",
    "    # Check the number of selected features\n",
    "    print(f\"Selected Features: {X_train_selected.shape[1]}\")\n",
    "\n",
    "    # Now you can proceed with training your model using selected features\n",
    "    # Train your model (for example, RandomForest, XGBoost, etc.) with X_train_selected\n",
    "    # and evaluate on X_valid_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a9a2adee-fc59-4b4e-a753-fc9e8c6bdaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9933\n",
      "Random Forest Accuracy: 0.9930\n",
      "Random Forest Accuracy: 0.9913\n",
      "Random Forest Accuracy: 0.9912\n",
      "Random Forest Accuracy: 0.9932\n",
      "Random Forest Accuracy: 0.9930\n",
      "Random Forest Accuracy: 0.9905\n",
      "Random Forest Accuracy: 0.9918\n",
      "Random Forest Accuracy: 0.9929\n",
      "Random Forest Accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# For each fold after SMOTE and feature selection\n",
    "for train_idx, valid_idx in skf.split(X, y_encoded):\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y_encoded[train_idx], y_encoded[valid_idx]\n",
    "\n",
    "    # Apply SMOTE on training portion\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Feature Selection using Random Forest model\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_train_smote, y_train_smote)\n",
    "    selector = SelectFromModel(rf, threshold=\"mean\", max_features=20, importance_getter=\"auto\")\n",
    "    X_train_selected = selector.transform(X_train_smote)\n",
    "    X_valid_selected = selector.transform(X_valid_fold)\n",
    "\n",
    "    # Train the Random Forest model on selected features\n",
    "    rf_model.fit(X_train_selected, y_train_smote)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_valid_pred = rf_model.predict(X_valid_selected)\n",
    "\n",
    "    # Evaluate performance (accuracy)\n",
    "    accuracy = accuracy_score(y_valid_fold, y_valid_pred)\n",
    "    print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536503dc-a9fb-4283-b434-f80befa00e01",
   "metadata": {},
   "source": [
    "Compute and print the mean and standard deviation of these accuracies.\n",
    "\n",
    "Save the selected features used in each fold and look for overlap â€” helps you identify consistently important features.\n",
    "\n",
    "Log a confusion matrix or classification report for one of the folds to see where errors occur (e.g., is Class III being confused with Class II?).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "07796c45-aaa7-4c57-b957-13c7b375cf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fold 1 ===\n",
      "XGBoost Accuracy: 0.9888\n",
      "=== Fold 2 ===\n",
      "XGBoost Accuracy: 0.9909\n",
      "=== Fold 3 ===\n",
      "XGBoost Accuracy: 0.9897\n",
      "=== Fold 4 ===\n",
      "XGBoost Accuracy: 0.9883\n",
      "=== Fold 5 ===\n",
      "XGBoost Accuracy: 0.9900\n",
      "=== Fold 6 ===\n",
      "XGBoost Accuracy: 0.9915\n",
      "=== Fold 7 ===\n",
      "XGBoost Accuracy: 0.9884\n",
      "=== Fold 8 ===\n",
      "XGBoost Accuracy: 0.9890\n",
      "=== Fold 9 ===\n",
      "XGBoost Accuracy: 0.9890\n",
      "=== Fold 10 ===\n",
      "XGBoost Accuracy: 0.9907\n",
      "\n",
      "=== Final XGBoost Cross-Validation Results ===\n",
      "Mean Accuracy: 0.9896 (Â±0.0010)\n"
     ]
    }
   ],
   "source": [
    "xgb_accuracies = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y_encoded), 1):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y_encoded[train_idx], y_encoded[valid_idx]\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Fit XGBoost\n",
    "    xgb = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "    xgb.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    importances = pd.Series(xgb.feature_importances_, index=X.columns)\n",
    "    top_features = importances.sort_values(ascending=False).head(20).index.tolist()\n",
    "    \n",
    "    X_train_selected = X_train_smote[top_features]\n",
    "    X_valid_selected = X_valid_fold[top_features]\n",
    "    \n",
    "    xgb_selected = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "    xgb_selected.fit(X_train_selected, y_train_smote)\n",
    "    \n",
    "    y_pred = xgb_selected.predict(X_valid_selected)\n",
    "    acc = accuracy_score(y_valid_fold, y_pred)\n",
    "    xgb_accuracies.append(acc)\n",
    "    \n",
    "    print(f\"XGBoost Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\n=== Final XGBoost Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(xgb_accuracies):.4f} (Â±{np.std(xgb_accuracies):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "40ce0c1d-f369-48f7-acf4-ffb2b1074d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fold 1 ===\n",
      "MLPClassifier Accuracy: 0.8691\n",
      "=== Fold 2 ===\n",
      "MLPClassifier Accuracy: 0.5839\n",
      "=== Fold 3 ===\n",
      "MLPClassifier Accuracy: 0.9590\n",
      "=== Fold 4 ===\n",
      "MLPClassifier Accuracy: 0.9744\n",
      "=== Fold 5 ===\n",
      "MLPClassifier Accuracy: 0.7477\n",
      "=== Fold 6 ===\n",
      "MLPClassifier Accuracy: 0.5456\n",
      "=== Fold 7 ===\n",
      "MLPClassifier Accuracy: 0.9716\n",
      "=== Fold 8 ===\n",
      "MLPClassifier Accuracy: 0.8776\n",
      "=== Fold 9 ===\n",
      "MLPClassifier Accuracy: 0.9666\n",
      "=== Fold 10 ===\n",
      "MLPClassifier Accuracy: 0.9716\n",
      "\n",
      "=== Final MLPClassifier Cross-Validation Results ===\n",
      "Mean Accuracy: 0.8467 (Â±0.1567)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "mlp_accuracies = []\n",
    "\n",
    "fold = 1\n",
    "for train_idx, valid_idx in skf.split(X, y_encoded):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y_encoded[train_idx], y_encoded[valid_idx]\n",
    "\n",
    "    # Apply SMOTE to training data\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Initialize MLPClassifier\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "    # Fit model\n",
    "    mlp.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = mlp.predict(X_valid_fold)\n",
    "    acc = accuracy_score(y_valid_fold, y_pred)\n",
    "    mlp_accuracies.append(acc)\n",
    "    print(f\"MLPClassifier Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "mean_acc = sum(mlp_accuracies) / len(mlp_accuracies)\n",
    "std_acc = (sum((x - mean_acc) ** 2 for x in mlp_accuracies) / len(mlp_accuracies)) ** 0.5\n",
    "\n",
    "print(\"\\n=== Final MLPClassifier Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {mean_acc:.4f} (Â±{std_acc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "14db3c8e-e24d-4063-bfb5-cdb6f914fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fold 1 ===\n",
      "CatBoost Accuracy: 0.9892\n",
      "=== Fold 2 ===\n",
      "CatBoost Accuracy: 0.9896\n",
      "=== Fold 3 ===\n",
      "CatBoost Accuracy: 0.9878\n",
      "=== Fold 4 ===\n",
      "CatBoost Accuracy: 0.9884\n",
      "=== Fold 5 ===\n",
      "CatBoost Accuracy: 0.9887\n",
      "=== Fold 6 ===\n",
      "CatBoost Accuracy: 0.9901\n",
      "=== Fold 7 ===\n",
      "CatBoost Accuracy: 0.9874\n",
      "=== Fold 8 ===\n",
      "CatBoost Accuracy: 0.9884\n",
      "=== Fold 9 ===\n",
      "CatBoost Accuracy: 0.9891\n",
      "=== Fold 10 ===\n",
      "CatBoost Accuracy: 0.9905\n",
      "\n",
      "=== Final CatBoost Cross-Validation Results ===\n",
      "Mean Accuracy: 0.9889 (Â±0.0009)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Set up cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "catboost_accuracies = []\n",
    "\n",
    "fold = 1\n",
    "for train_idx, valid_idx in skf.split(X, y_encoded):\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y_encoded[train_idx], y_encoded[valid_idx]\n",
    "\n",
    "    # Apply SMOTE\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Initialize CatBoost (silent training)\n",
    "    cat_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "\n",
    "    # Fit and predict\n",
    "    cat_model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred = cat_model.predict(X_valid_fold)\n",
    "\n",
    "    # Evaluate\n",
    "    acc = accuracy_score(y_valid_fold, y_pred)\n",
    "    catboost_accuracies.append(acc)\n",
    "    print(f\"CatBoost Accuracy: {acc:.4f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "mean_acc = sum(catboost_accuracies) / len(catboost_accuracies)\n",
    "std_acc = (sum((x - mean_acc) ** 2 for x in catboost_accuracies) / len(catboost_accuracies)) ** 0.5\n",
    "\n",
    "print(\"\\n=== Final CatBoost Cross-Validation Results ===\")\n",
    "print(f\"Mean Accuracy: {mean_acc:.4f} (Â±{std_acc:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "37965e33-7eaa-4f72-895b-7523927f1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Best Random Forest Params: {'max_depth': 25, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 174}\n",
      "Best Accuracy: 0.9919\n",
      "Tuning Time: 608.12 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "rf_random_search.fit(X, y)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nBest Random Forest Params: {rf_random_search.best_params_}\")\n",
    "print(f\"Best Accuracy: {rf_random_search.best_score_:.4f}\")\n",
    "print(f\"Tuning Time: {end - start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2311f730-52b2-4c25-9d2f-73f30231ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-10 23:20:25,217] A new study created in memory with name: no-name-7c80adcc-3671-4eac-9a1b-6781e3be41af\n",
      "[I 2025-04-10 23:21:02,337] Trial 0 finished with value: 0.9867218826004075 and parameters: {'iterations': 323, 'depth': 9, 'learning_rate': 0.05499635560911883, 'l2_leaf_reg': 6.088201699358175, 'random_strength': 0.2536876811795584, 'border_count': 196}. Best is trial 0 with value: 0.9867218826004075.\n",
      "[I 2025-04-10 23:21:14,897] Trial 1 finished with value: 0.9734043252481431 and parameters: {'iterations': 242, 'depth': 5, 'learning_rate': 0.01134061009680689, 'l2_leaf_reg': 1.1795192959426974, 'random_strength': 0.7508737219380018, 'border_count': 58}. Best is trial 0 with value: 0.9867218826004075.\n",
      "[I 2025-04-10 23:21:38,819] Trial 2 finished with value: 0.9884309472161966 and parameters: {'iterations': 436, 'depth': 6, 'learning_rate': 0.1515952932447508, 'l2_leaf_reg': 4.054509983652165, 'random_strength': 0.8871152507039605, 'border_count': 149}. Best is trial 2 with value: 0.9884309472161966.\n",
      "[I 2025-04-10 23:21:49,490] Trial 3 finished with value: 0.9818444751199632 and parameters: {'iterations': 204, 'depth': 5, 'learning_rate': 0.07871000679211161, 'l2_leaf_reg': 1.2614409004199048, 'random_strength': 0.4550695555219315, 'border_count': 57}. Best is trial 2 with value: 0.9884309472161966.\n",
      "[I 2025-04-10 23:22:16,327] Trial 4 finished with value: 0.9852626043515414 and parameters: {'iterations': 485, 'depth': 6, 'learning_rate': 0.06444070981430657, 'l2_leaf_reg': 9.411272800026241, 'random_strength': 0.28194304995838204, 'border_count': 178}. Best is trial 2 with value: 0.9884309472161966.\n",
      "[I 2025-04-10 23:22:51,616] Trial 5 finished with value: 0.9788601853677775 and parameters: {'iterations': 322, 'depth': 9, 'learning_rate': 0.013990241705658745, 'l2_leaf_reg': 3.348921957500847, 'random_strength': 0.8710527676865084, 'border_count': 191}. Best is trial 2 with value: 0.9884309472161966.\n",
      "[I 2025-04-10 23:23:15,595] Trial 6 finished with value: 0.9896798790508118 and parameters: {'iterations': 428, 'depth': 6, 'learning_rate': 0.22155145917629243, 'l2_leaf_reg': 1.885092491864421, 'random_strength': 0.36700743073964937, 'border_count': 229}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:23:35,461] Trial 7 finished with value: 0.9788864786695589 and parameters: {'iterations': 399, 'depth': 5, 'learning_rate': 0.0208389673834665, 'l2_leaf_reg': 3.905523598093381, 'random_strength': 0.48979189879787854, 'border_count': 184}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:23:59,400] Trial 8 finished with value: 0.9865115361861566 and parameters: {'iterations': 487, 'depth': 5, 'learning_rate': 0.08542955576034475, 'l2_leaf_reg': 3.410137979041643, 'random_strength': 0.5621320661724214, 'border_count': 152}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:24:10,041] Trial 9 finished with value: 0.9793991980542958 and parameters: {'iterations': 197, 'depth': 5, 'learning_rate': 0.04848005603922967, 'l2_leaf_reg': 4.345353309601634, 'random_strength': 0.16785734587799234, 'border_count': 252}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:24:20,688] Trial 10 finished with value: 0.9874055084467234 and parameters: {'iterations': 103, 'depth': 8, 'learning_rate': 0.27224273330796234, 'l2_leaf_reg': 7.3100355779283905, 'random_strength': 0.6510627928610059, 'border_count': 253}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:24:45,854] Trial 11 finished with value: 0.9895747058436862 and parameters: {'iterations': 407, 'depth': 7, 'learning_rate': 0.27984689501943066, 'l2_leaf_reg': 2.629483245814534, 'random_strength': 0.9931493072787351, 'border_count': 116}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:25:10,871] Trial 12 finished with value: 0.9896667323999211 and parameters: {'iterations': 397, 'depth': 7, 'learning_rate': 0.2788739467425275, 'l2_leaf_reg': 2.4192391127111796, 'random_strength': 0.9994403583922786, 'border_count': 102}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:25:33,652] Trial 13 finished with value: 0.9890225465062775 and parameters: {'iterations': 360, 'depth': 7, 'learning_rate': 0.15879478977529338, 'l2_leaf_reg': 2.451692316885172, 'random_strength': 0.35875760018264996, 'border_count': 98}. Best is trial 6 with value: 0.9896798790508118.\n",
      "[I 2025-04-10 23:27:09,655] Trial 14 finished with value: 0.9897587589561561 and parameters: {'iterations': 446, 'depth': 10, 'learning_rate': 0.14434261761371373, 'l2_leaf_reg': 5.150577525913404, 'random_strength': 0.6854259570719053, 'border_count': 102}. Best is trial 14 with value: 0.9897587589561561.\n",
      "[I 2025-04-10 23:28:40,678] Trial 15 finished with value: 0.9897850522579373 and parameters: {'iterations': 452, 'depth': 10, 'learning_rate': 0.13471139496824774, 'l2_leaf_reg': 5.988581181994652, 'random_strength': 0.6291669384495817, 'border_count': 228}. Best is trial 15 with value: 0.9897850522579373.\n",
      "[I 2025-04-10 23:30:00,929] Trial 16 finished with value: 0.9884440938670874 and parameters: {'iterations': 496, 'depth': 10, 'learning_rate': 0.11839546465859413, 'l2_leaf_reg': 5.805011289435372, 'random_strength': 0.7086810751584949, 'border_count': 34}. Best is trial 15 with value: 0.9897850522579373.\n",
      "[I 2025-04-10 23:30:55,887] Trial 17 finished with value: 0.9848156182212582 and parameters: {'iterations': 359, 'depth': 10, 'learning_rate': 0.033046879293501426, 'l2_leaf_reg': 7.340039103004712, 'random_strength': 0.6717031373261784, 'border_count': 123}. Best is trial 15 with value: 0.9897850522579373.\n",
      "[I 2025-04-10 23:31:27,975] Trial 18 finished with value: 0.9879313744823506 and parameters: {'iterations': 267, 'depth': 9, 'learning_rate': 0.10410068707067259, 'l2_leaf_reg': 6.903037416058061, 'random_strength': 0.588173024143928, 'border_count': 213}. Best is trial 15 with value: 0.9897850522579373.\n",
      "[I 2025-04-10 23:32:46,832] Trial 19 finished with value: 0.9895352658910144 and parameters: {'iterations': 452, 'depth': 10, 'learning_rate': 0.16411117367767059, 'l2_leaf_reg': 8.687383460096711, 'random_strength': 0.8260794096400079, 'border_count': 80}. Best is trial 15 with value: 0.9897850522579373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost Params: {'iterations': 452, 'depth': 10, 'learning_rate': 0.13471139496824774, 'l2_leaf_reg': 5.988581181994652, 'random_strength': 0.6291669384495817, 'border_count': 228}\n",
      "Best Accuracy: 0.9897850522579373\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna\n",
    "\n",
    "def catboost_objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 500),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 1),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\")\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(catboost_objective, n_trials=20)\n",
    "\n",
    "print(\"Best CatBoost Params:\", study.best_params)\n",
    "print(\"Best Accuracy:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b10cd487-1506-4785-91a5-bc78afe45a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Params: {'solver': 'adam', 'max_iter': 500, 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'alpha': 1e-05, 'activation': 'relu'}\n",
      "Best Accuracy: 0.9387366068494052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [1e-5, 1e-4, 1e-3],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [300, 500]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp_search = RandomizedSearchCV(mlp, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "mlp_search.fit(X, y)\n",
    "\n",
    "print(\"Best MLP Params:\", mlp_search.best_params_)\n",
    "print(\"Best Accuracy:\", mlp_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ed8564d8-b8c8-4f3c-8c66-1a6bafe1a976",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t1/yg1rln0x5bg97h_qn954mvlh0000gn/T/ipykernel_1628/1357742818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Time it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mxgb_random_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_routed_params_for_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mcv_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrouted_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_estimator_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_tags.py\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"__sklearn_tags__\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0msklearn_tags_provider\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0mclass_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"_more_tags\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierTags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "import time\n",
    "\n",
    "# Define the model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Parameter grid\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "xgb_random_search.fit(X, y)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nBest XGBoost Params: {xgb_random_search.best_params_}\")\n",
    "print(f\"Best Accuracy: {xgb_random_search.best_score_:.4f}\")\n",
    "print(f\"Tuning Time: {end - start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cd6da-26f5-4cf0-b267-dd91d122de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load Datasets \n",
    "train_df = pd.read_csv('/Users/parisakamizi/Downloads/datasets/train_hybrid.csv')\n",
    "test_df = pd.read_csv('/Users/parisakamizi/Downloads/datasets/test_hybrid.csv')\n",
    "\n",
    "# Separate Features and Target \n",
    "X_train = train_df.drop('Event Classification', axis=1)\n",
    "y_train = train_df['Event Classification']\n",
    "X_test = test_df.drop('Event Classification', axis=1)\n",
    "y_test = test_df['Event Classification']\n",
    "\n",
    "# Encode Categorical Features \n",
    "# One-Hot Encoding \n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Ensure test data has same columns as train data\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Encode Target Variable \n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Apply SMOTE to Handle Imbalance \n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = sm.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "# Final Model Training \n",
    "final_rf = RandomForestClassifier(\n",
    "    n_estimators=174,\n",
    "    max_depth=25,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=None,\n",
    "    random_state=42\n",
    ")\n",
    "final_rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Final Evaluation \n",
    "y_pred = final_rf.predict(X_test)\n",
    "acc = accuracy_score(y_test_encoded, y_pred)\n",
    "report = classification_report(y_test_encoded, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "\n",
    "print(f\"Final Test Accuracy: {acc:.4f}\")\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(report)\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f3fd7-6c3a-40d9-bc71-1f4ab532f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get feature importances\n",
    "importances = final_rf.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(15), palette='viridis')\n",
    "plt.title('Top 15 Feature Importances (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133427d0-688f-42f7-8c03-cdf42ff101d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "catboost_preds = best_cat.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "catboost_test_accuracy = accuracy_score(y_test, catboost_preds)\n",
    "print(f\"CatBoost Test Accuracy: {catboost_test_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (CatBoost):\")\n",
    "print(classification_report(y_test, catboost_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, catboost_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd368ee7-84fa-432e-b33d-3f6ab3bb8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "xgb_preds = best_xgb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "xgb_test_accuracy = accuracy_score(y_test, xgb_preds)\n",
    "print(f\"XGBoost Test Accuracy: {xgb_test_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (XGBoost):\")\n",
    "print(classification_report(y_test, xgb_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix (XGBoost):\")\n",
    "print(confusion_matrix(y_test, xgb_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e06c81-c83b-4428-be6f-c8111c145d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "mlp_preds = best_mlp.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "mlp_test_accuracy = accuracy_score(y_test, mlp_preds)\n",
    "print(f\"MLPClassifier Test Accuracy: {mlp_test_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (MLPClassifier):\")\n",
    "print(classification_report(y_test, mlp_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix (MLPClassifier):\")\n",
    "print(confusion_matrix(y_test, mlp_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04e780-cf9b-4452-9181-a01de3841cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_conf_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {title}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "# Confusion Matrix for XGBoost\n",
    "plot_conf_matrix(y_test, y_pred_xgb, \"XGBoost\")\n",
    "\n",
    "# Confusion Matrix for MLPClassifier\n",
    "plot_conf_matrix(y_test, y_pred_mlp, \"MLPClassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6433447-89e5-4c81-81e3-f6e0b07206f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report as Heatmap\n",
    "def plot_classification_report(y_true, y_pred, title):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    df = pd.DataFrame(report).iloc[:-1, :].T  # Exclude 'accuracy' row\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df, annot=True, cmap=\"YlGnBu\")\n",
    "    plt.title(f\"Classification Report - {title}\")\n",
    "    plt.show()\n",
    "\n",
    "# XGBoost Report\n",
    "plot_classification_report(y_test, y_pred_xgb, \"XGBoost\")\n",
    "\n",
    "# MLPClassifier Report\n",
    "plot_classification_report(y_test, y_pred_mlp, \"MLPClassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5f534-11c7-4cdd-afed-256e2faab025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy comparison\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=[\"XGBoost\", \"MLPClassifier\"], y=[acc_xgb, acc_mlp], palette=\"pastel\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d31126-1ca0-4089-904d-fdece513b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for CatBoost\n",
    "plot_conf_matrix(y_test, y_pred_catboost, \"CatBoost\")\n",
    "\n",
    "# Confusion Matrix for Random Forest\n",
    "plot_conf_matrix(y_test, y_pred_rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab28db-173f-4d62-98a6-a9943b4f4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Report\n",
    "plot_classification_report(y_test, y_pred_catboost, \"CatBoost\")\n",
    "\n",
    "# Random Forest Report\n",
    "plot_classification_report(y_test, y_pred_rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e539fc-3fdb-486c-96ef-cb6721cbfd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy scores\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "acc_cat = accuracy_score(y_test, y_pred_catboost)\n",
    "\n",
    "# Extended bar chart with all models\n",
    "model_names = [\"Random Forest\", \"CatBoost\", \"XGBoost\", \"MLPClassifier\"]\n",
    "accuracies = [acc_rf, acc_cat, acc_xgb, acc_mlp]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=model_names, y=accuracies, palette=\"pastel\")\n",
    "plt.title(\"Accuracy Comparison Across Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343aaaa-3d6e-4b5d-ba8a-335f14e18656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Confusion Matrices (Counts and Normalized)\n",
    "for model_name, y_pred in zip(\n",
    "    [\"Random Forest\", \"CatBoost\", \"XGBoost\", \"MLPClassifier\"],\n",
    "    [y_pred_rf, y_pred_catboost, y_pred_xgb, y_pred_mlp]\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax[0], cmap=\"Blues\")\n",
    "    ax[0].set_title(f\"{model_name} - Confusion Matrix (Counts)\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize='true', ax=ax[1], cmap=\"Oranges\")\n",
    "    ax[1].set_title(f\"{model_name} - Confusion Matrix (Normalized)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227058f6-f4bb-498c-8d95-000592de5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_class_report(y_true, y_pred, title):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    df_report = pd.DataFrame(report).iloc[:-1, :].T  # drop accuracy row\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.heatmap(df_report, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "    plt.title(f\"{title} - Classification Report\")\n",
    "    plt.ylabel(\"Metrics\")\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot for all models\n",
    "plot_class_report(y_test, y_pred_rf, \"Random Forest\")\n",
    "plot_class_report(y_test, y_pred_catboost, \"CatBoost\")\n",
    "plot_class_report(y_test, y_pred_xgb, \"XGBoost\")\n",
    "plot_class_report(y_test, y_pred_mlp, \"MLPClassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c4f091-7de4-4ff0-8300-0bd9686320e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy scores\n",
    "accuracies = {\n",
    "    \"Random Forest\": accuracy_score(y_test, y_pred_rf),\n",
    "    \"CatBoost\": accuracy_score(y_test, y_pred_catboost),\n",
    "    \"XGBoost\": accuracy_score(y_test, y_pred_xgb),\n",
    "    \"MLPClassifier\": accuracy_score(y_test, y_pred_mlp)\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=\"pastel\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c170b769-34cf-4b74-9745-01bb3f357542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "importances_rf = pd.Series(best_rf_model.feature_importances_, index=X_test.columns)\n",
    "importances_rf.sort_values().tail(10).plot(kind=\"barh\", title=\"Random Forest - Top Features\", figsize=(8, 4))\n",
    "plt.show()\n",
    "\n",
    "# CatBoost\n",
    "importances_cat = pd.Series(best_cat_model.get_feature_importance(), index=X_test.columns)\n",
    "importances_cat.sort_values().tail(10).plot(kind=\"barh\", title=\"CatBoost - Top Features\", figsize=(8, 4))\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "importances_xgb = pd.Series(best_xgb_model.feature_importances_, index=X_test.columns)\n",
    "importances_xgb.sort_values().tail(10).plot(kind=\"barh\", title=\"XGBoost - Top Features\", figsize=(8, 4))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ed0f5-15d4-4f25-ab8f-c5c07b2bb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Binarize the output\n",
    "classes = np.unique(y_test)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "def plot_roc(model, X_test, y_test_bin, name):\n",
    "    y_score = model.predict_proba(X_test)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for i in range(len(classes)):\n",
    "        plt.plot(fpr[i], tpr[i], label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title(f\"Multi-class ROC Curve - {name}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# For tree-based models\n",
    "plot_roc(best_rf_model, X_test, y_test_bin, \"Random Forest\")\n",
    "plot_roc(best_cat_model, X_test, y_test_bin, \"CatBoost\")\n",
    "plot_roc(best_xgb_model, X_test, y_test_bin, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749085fa-2f24-4eaf-8d6a-695a64f383e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting performance metrics for each model\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Creating a dictionary to store metrics\n",
    "performance = {}\n",
    "\n",
    "for model_name, y_pred in zip(\n",
    "    [\"Random Forest\", \"CatBoost\", \"XGBoost\", \"MLPClassifier\"],\n",
    "    [y_pred_rf, y_pred_catboost, y_pred_xgb, y_pred_mlp]\n",
    "):\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    performance[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision (Class 0)\": report[\"0\"][\"precision\"],\n",
    "        \"Precision (Class 1)\": report[\"1\"][\"precision\"],\n",
    "        \"Precision (Class 2)\": report[\"2\"][\"precision\"],\n",
    "        \"Recall (Class 0)\": report[\"0\"][\"recall\"],\n",
    "        \"Recall (Class 1)\": report[\"1\"][\"recall\"],\n",
    "        \"Recall (Class 2)\": report[\"2\"][\"recall\"],\n",
    "        \"F1 (Class 0)\": report[\"0\"][\"f1-score\"],\n",
    "        \"F1 (Class 1)\": report[\"1\"][\"f1-score\"],\n",
    "        \"F1 (Class 2)\": report[\"2\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "# Creating DataFrame for better visualization\n",
    "performance_df = pd.DataFrame(performance).T\n",
    "performance_df = performance_df.round(4)  # Rounding for clarity\n",
    "\n",
    "# Displaying the performance table\n",
    "print(\"Final Model Performance Summary:\")\n",
    "print(performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914bbb03-9337-4616-af90-4746d7e45aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving performance summary to a CSV file\n",
    "performance_df.to_csv(\"model_performance_summary.csv\", index=True)\n",
    "print(\"Performance summary exported as 'model_performance_summary.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013db028-c8e5-4b88-8e29-253997970303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrix plots\n",
    "for model_name, y_pred in zip(\n",
    "    [\"Random Forest\", \"CatBoost\", \"XGBoost\", \"MLPClassifier\"],\n",
    "    [y_pred_rf, y_pred_catboost, y_pred_xgb, y_pred_mlp]\n",
    "):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax[0], cmap=\"Blues\")\n",
    "    ax[0].set_title(f\"{model_name} - Confusion Matrix (Counts)\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, normalize='true', ax=ax[1], cmap=\"Oranges\")\n",
    "    ax[1].set_title(f\"{model_name} - Confusion Matrix (Normalized)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name}_confusion_matrix.png\")\n",
    "\n",
    "# Save Classification Report Heatmaps\n",
    "for model_name, y_pred in zip(\n",
    "    [\"Random Forest\", \"CatBoost\", \"XGBoost\", \"MLPClassifier\"],\n",
    "    [y_pred_rf, y_pred_catboost, y_pred_xgb, y_pred_mlp]\n",
    "):\n",
    "    plot_class_report(y_test, y_pred, model_name)\n",
    "    plt.savefig(f\"{model_name}_classification_report_heatmap.png\")\n",
    "\n",
    "# Save Feature Importance Plots\n",
    "importances_rf.sort_values().tail(10).plot(kind=\"barh\", title=\"Random Forest - Top Features\", figsize=(8, 4))\n",
    "plt.savefig(\"Random_Forest_feature_importance.png\")\n",
    "importances_cat.sort_values().tail(10).plot(kind=\"barh\", title=\"CatBoost - Top Features\", figsize=(8, 4))\n",
    "plt.savefig(\"CatBoost_feature_importance.png\")\n",
    "importances_xgb.sort_values().tail(10).plot(kind=\"barh\", title=\"XGBoost - Top Features\", figsize=(8, 4))\n",
    "plt.savefig(\"XGBoost_feature_importance.png\")\n",
    "\n",
    "# Save ROC Curves\n",
    "plot_roc(best_rf_model, X_test, y_test_bin, \"Random Forest\")\n",
    "plt.savefig(\"Random_Forest_ROC_curve.png\")\n",
    "plot_roc(best_cat_model, X_test, y_test_bin, \"CatBoost\")\n",
    "plt.savefig(\"CatBoost_ROC_curve.png\")\n",
    "plot_roc(best_xgb_model, X_test, y_test_bin, \"XGBoost\")\n",
    "plt.savefig(\"XGBoost_ROC_curve.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
