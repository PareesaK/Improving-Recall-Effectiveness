{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74685e9d-70f4-4815-8052-737291970f0b",
   "metadata": {},
   "source": [
    "# FDA Recall Classification Pipeline: Model Development and Evaluation\n",
    "**By Lorena Dorado & Parisa Kamizi**\n",
    "\n",
    "- This notebook implements modeling with multiple algorithms (Logistic Regression, Decision Tree, Random Forest, XGBoost, MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4f8d7d-2d78-4cf0-9c55-963f8cb6c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from scipy.stats import randint, uniform, sem, t\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, auc,\n",
    "    roc_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ab854e-136b-4778-b0e7-7335cbb1020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for saving results and cached models\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('results/baseline', exist_ok=True)\n",
    "os.makedirs('results/hybrid', exist_ok=True)\n",
    "os.makedirs('cache', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a34318e-9f25-471a-92fe-11ef179953df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "dataset_type = 'baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d065903-f4d7-4278-b60f-45e710a95121",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc892296-8b5c-4ec7-ac31-98b0fc426f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded baseline datasets:\n",
      "Training shape: (31492, 42)\n",
      "Testing shape: (7874, 42)\n",
      "Test set proportion: 20.00%\n",
      "\n",
      "Training Dataset Overview:\n",
      "Columns: 42\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_path = f'../data/train_{dataset_type}.csv'\n",
    "test_path = f'../data/test_{dataset_type}.csv'\n",
    "try:\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    print(f\"Loaded {dataset_type} datasets:\")\n",
    "    print(f\"Training shape: {train_df.shape}\")\n",
    "    print(f\"Testing shape: {test_df.shape}\")\n",
    "    print(\"Test set proportion: {:.2f}%\".format(100 * X_test.shape[0] / (X_train.shape[0] + X_test.shape[0])))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {dataset_type} datasets not found. Please run Data Processing Notebook.ipynb\")\n",
    "    raise SystemExit(\"Aborting execution.\")\n",
    "else:\n",
    "    # Basic dataset information\n",
    "    print(\"\\nTraining Dataset Overview:\")\n",
    "    print(f\"Columns: {len(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fa042-e345-4edb-9840-ac3cf2ee70ed",
   "metadata": {},
   "source": [
    "## Data Cleaning (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30f65fc1-8dd3-4f68-bdf6-40f7232ba5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in training data\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing = train_df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "print(f\"Missing values in training data: {missing}\" if not missing.empty else \"No missing values in training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf269d37-d390-4c9c-b4d3-7101866e08c5",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c105011c-ff1e-44d7-a10b-e3dd7208415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X_train = train_df.drop(target_col, axis=1)\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df.drop(target_col, axis=1)\n",
    "y_test = test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76ce0f68-df38-400d-b1c2-2c2d0cd0e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check test data has the same columns as train data\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cde9fe88-ca57-48fe-92f8-f59a883c78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: ['Class I' 'Class II' 'Class III']\n",
      "Encoded as: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "class_names = le.classes_\n",
    "print(f\"Target Classes: {class_names}\")\n",
    "print(f\"Encoded as: {np.unique(y_train_encoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f56d53b-f7c2-4eee-84b1-eee644c79b53",
   "metadata": {},
   "source": [
    "## Train-Test Split Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a861093-2805-4582-bb14-c35909b6b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training class distribution (counts):\n",
      "1    22619\n",
      "0     6684\n",
      "2     2189\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training class distribution (percentages):\n",
      "1    71.824590\n",
      "0    21.224438\n",
      "2     6.950972\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test class distribution (counts):\n",
      "1    5655\n",
      "0    1671\n",
      "2     548\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution (percentages):\n",
      "1    71.818644\n",
      "0    21.221742\n",
      "2     6.959614\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution analysis\n",
    "train_class_counts = pd.Series(y_train_encoded).value_counts()\n",
    "test_class_counts = pd.Series(y_test_encoded).value_counts()\n",
    "print(\"\\nTraining class distribution (counts):\")\n",
    "print(train_class_counts)\n",
    "print(\"\\nTraining class distribution (percentages):\")\n",
    "print(pd.Series(y_train_encoded).value_counts(normalize=True) * 100)\n",
    "print(\"\\nTest class distribution (counts):\")\n",
    "print(test_class_counts)\n",
    "print(\"\\nTest class distribution (percentages):\")\n",
    "print(pd.Series(y_test_encoded).value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44594fb8-64c5-4b61-ba47-aa7dd96e5ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features: 41\n"
     ]
    }
   ],
   "source": [
    "# Display number of features\n",
    "print(f\"\\nNumber of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81074854-0342-4339-8966-63da33edfd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features: 5\n",
      "Categorical features: 16\n",
      "Flag features: 19\n",
      "Other features: 1\n"
     ]
    }
   ],
   "source": [
    "# Display feature categories\n",
    "temporal_features = [col for col in X_train.columns if any(x in col for x in ['Month', 'Day', 'Year', 'Week'])]\n",
    "categorical_features = [col for col in X_train.columns if any(x in col for x in ['Type', 'Status', 'Region', 'DistScope'])]\n",
    "flag_features = [col for col in X_train.columns if any(x in col for x in ['has_', 'allergen_', 'possible_'])]\n",
    "print(f\"Temporal features: {len(temporal_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "print(f\"Flag features: {len(flag_features)}\")\n",
    "print(f\"Other features: {X_train.shape[1] - len(temporal_features) - len(categorical_features) - len(flag_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b24a2-6cd6-4b96-a941-5a54b5be6211",
   "metadata": {},
   "source": [
    "Pre-processed Dataset Validation: Checking infinity or NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26ccb011-6222-4133-9c58-cc41f40d8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No infinity or NaN values found.\n"
     ]
    }
   ],
   "source": [
    "# Check for issues\n",
    "inf_count = np.isinf(X_train.values).sum()\n",
    "nan_count = np.isnan(X_train.values).sum()\n",
    "if inf_count > 0 or nan_count > 0:\n",
    "    print(f\"Warning: Found {inf_count} infinity values and {nan_count} NaN values\")\n",
    "    # Handle issues\n",
    "    X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "else:\n",
    "    print(\"No infinity or NaN values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16282acf-2de8-4de1-beb8-6afd7ed32712",
   "metadata": {},
   "source": [
    "# Modeling with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f72474b-aa69-4ff0-b5aa-3a906162c56a",
   "metadata": {},
   "source": [
    "The models selected includ logistic regression (logreg), decision tree, random forest, xgboost, and multi-layer perceptron (mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9667ed2-3a5b-4e1b-b5f4-71adbf0a08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'logreg': {\n",
    "        'model': LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
    "        'param_grid': {\n",
    "            'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "            'model__penalty': ['l1', 'l2']\n",
    "        },\n",
    "        'needs_scaling': True,\n",
    "        'feature_selector': SelectFromModel\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'model__max_depth': [5, 10, 15, 20, None],\n",
    "            'model__min_samples_split': [2, 5, 10],\n",
    "            'model__min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        'needs_scaling': False,\n",
    "        'feature_selector': SelectFromModel\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'param_grid': {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [10, 20, None],\n",
    "            'model__min_samples_split': [2, 5],\n",
    "            'model__min_samples_leaf': [1, 2]\n",
    "        },\n",
    "        'needs_scaling': False,\n",
    "        'feature_selector': SelectFromModel\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'model': XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', random_state=42),\n",
    "        'param_grid': {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__learning_rate': [0.01, 0.1],\n",
    "            'model__max_depth': [3, 6],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0]\n",
    "        },\n",
    "        'needs_scaling': False,\n",
    "        'feature_selector': SelectFromModel\n",
    "    },\n",
    "    'mlp': {\n",
    "        'model': MLPClassifier(max_iter=1000, random_state=42),\n",
    "        'param_grid': {\n",
    "            'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'model__activation': ['relu', 'tanh'],\n",
    "            'model__alpha': [0.0001, 0.001],\n",
    "            'model__learning_rate': ['constant', 'adaptive']\n",
    "        },\n",
    "        'needs_scaling': True,\n",
    "        'feature_selector': SelectKBest\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "395d3e6d-9398-4972-a688-08fbced1c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of features\n",
    "n_features_options = [5, 10, 15, 20, 'all']  # 'all' = no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1fda377-4001-44ad-873a-ac61ac831127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of cross-validation folds\n",
    "n_cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4ca08-0ee6-4012-ad30-dbcbafa07972",
   "metadata": {},
   "source": [
    "Stratified k-fold for consistent fold splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0aa3f82-e341-4bb8-9b88-91c293c627f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define skf\n",
    "skf = StratifiedKFold(n_splits=n_cv_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f880648-d447-464d-a97f-b21201b940e8",
   "metadata": {},
   "source": [
    "Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76261edd-e2ca-4957-9be8-15280f71f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Dictionary\n",
    "results = defaultdict(list)\n",
    "best_configs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499b870-7fba-4098-928d-676af34b7ff9",
   "metadata": {},
   "source": [
    "Track feature selection frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e63288df-cebf-42f3-a839-d0a4a9a86608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "feature_importance = pd.DataFrame(0, index=X_train.columns, columns=list(models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1eac9c-2d40-46c5-8020-3f49be5ae85b",
   "metadata": {},
   "source": [
    "Iterate through each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6434fa-67d6-4b92-8c71-bdcf9050b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating logreg...\n",
      "  Testing with feature selection: 5\n",
      "    Fold 1/5\n",
      "      Best params: {'model__C': 0.01, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5934\n",
      "    Fold 2/5\n",
      "      Best params: {'model__C': 0.01, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5917\n",
      "    Fold 3/5\n",
      "      Best params: {'model__C': 0.01, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5915\n",
      "    Fold 4/5\n",
      "      Best params: {'model__C': 0.01, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.5978\n",
      "    Fold 5/5\n",
      "      Best params: {'model__C': 0.01, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.5904\n",
      "  Mean F1 Score for 5 features: 0.5930 (±0.0026)\n",
      "  Testing with feature selection: 10\n",
      "    Fold 1/5\n",
      "      Best params: {'model__C': 100, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6704\n",
      "    Fold 2/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5837\n",
      "    Fold 3/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5934\n",
      "    Fold 4/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6405\n",
      "    Fold 5/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.5975\n",
      "  Mean F1 Score for 10 features: 0.6171 (±0.0330)\n",
      "  Testing with feature selection: 15\n",
      "    Fold 1/5\n",
      "      Best params: {'model__C': 100, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6704\n",
      "    Fold 2/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5837\n",
      "    Fold 3/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5934\n",
      "    Fold 4/5\n",
      "      Best params: {'model__C': 0.1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6475\n",
      "    Fold 5/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.5975\n",
      "  Mean F1 Score for 15 features: 0.6185 (±0.0341)\n",
      "  Testing with feature selection: 20\n",
      "    Fold 1/5\n",
      "      Best params: {'model__C': 100, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6704\n",
      "    Fold 2/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5837\n",
      "    Fold 3/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.5934\n",
      "    Fold 4/5\n",
      "      Best params: {'model__C': 0.1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6475\n",
      "    Fold 5/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.5975\n",
      "  Mean F1 Score for 20 features: 0.6185 (±0.0341)\n",
      "  Testing with feature selection: all\n",
      "    Fold 1/5\n",
      "      Best params: {'model__C': 1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6922\n",
      "    Fold 2/5\n",
      "      Best params: {'model__C': 10, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6776\n",
      "    Fold 3/5\n",
      "      Best params: {'model__C': 0.01, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.6955\n",
      "    Fold 4/5\n",
      "      Best params: {'model__C': 0.1, 'model__penalty': 'l1'}\n",
      "      Validation F1 Score: 0.6925\n",
      "    Fold 5/5\n",
      "      Best params: {'model__C': 0.1, 'model__penalty': 'l2'}\n",
      "      Validation F1 Score: 0.6894\n",
      "  Mean F1 Score for all features: 0.6894 (±0.0062)\n",
      "\n",
      "Best configuration for logreg:\n",
      "  Number of features: all\n",
      "  Best parameters: {'model__C': 0.1, 'model__penalty': 'l2'}\n",
      "  Best CV F1 Score: 0.6894\n",
      "  Most important features: ProductType_Devices, ProductType_Drugs, ProductType_Food/Cosmetics, ProductType_Veterinary, DistScope_Nationwide\n",
      "\n",
      "Training and evaluating decision_tree...\n",
      "  Testing with feature selection: 5\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.7641\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.7717\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.7564\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8249\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.7712\n",
      "  Mean F1 Score for 5 features: 0.7777 (±0.0243)\n",
      "  Testing with feature selection: 10\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8827\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8819\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8812\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8864\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8870\n",
      "  Mean F1 Score for 10 features: 0.8838 (±0.0024)\n",
      "  Testing with feature selection: 15\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8889\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8869\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8868\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8845\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8929\n",
      "  Mean F1 Score for 15 features: 0.8880 (±0.0028)\n",
      "  Testing with feature selection: 20\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8889\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8869\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8868\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8845\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8929\n",
      "  Mean F1 Score for 20 features: 0.8880 (±0.0028)\n",
      "  Testing with feature selection: all\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8972\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8940\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8991\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.8992\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "      Validation F1 Score: 0.9035\n",
      "  Mean F1 Score for all features: 0.8986 (±0.0031)\n",
      "\n",
      "Best configuration for decision_tree:\n",
      "  Number of features: all\n",
      "  Best parameters: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n",
      "  Best CV F1 Score: 0.8986\n",
      "  Most important features: Month_sin, Month_cos, DayOfWeek_sin, DayOfWeek_cos, Years_Since_First\n",
      "\n",
      "Training and evaluating random_forest...\n",
      "  Testing with feature selection: 5\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8300\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8231\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8204\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8245\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "      Validation F1 Score: 0.8300\n",
      "  Mean F1 Score for 5 features: 0.8256 (±0.0038)\n",
      "  Testing with feature selection: 10\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8976\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8997\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8938\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8947\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.8996\n",
      "  Mean F1 Score for 10 features: 0.8971 (±0.0025)\n",
      "  Testing with feature selection: 15\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9096\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9127\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9048\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9052\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9148\n",
      "  Mean F1 Score for 15 features: 0.9094 (±0.0040)\n",
      "  Testing with feature selection: 20\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9096\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9127\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9048\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9052\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9148\n",
      "  Mean F1 Score for 20 features: 0.9094 (±0.0040)\n",
      "  Testing with feature selection: all\n",
      "    Fold 1/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9208\n",
      "    Fold 2/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9214\n",
      "    Fold 3/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9178\n",
      "    Fold 4/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9193\n",
      "    Fold 5/5\n",
      "      Best params: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "      Validation F1 Score: 0.9281\n",
      "  Mean F1 Score for all features: 0.9215 (±0.0035)\n",
      "\n",
      "Best configuration for random_forest:\n",
      "  Number of features: all\n",
      "  Best parameters: {'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "  Best CV F1 Score: 0.9215\n",
      "  Most important features: Month_sin, Month_cos, DayOfWeek_sin, DayOfWeek_cos, Years_Since_First\n",
      "\n",
      "Training and evaluating xgboost...\n",
      "  Testing with feature selection: 5\n",
      "    Fold 1/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.6719\n",
      "    Fold 2/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.5916\n",
      "    Fold 3/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.5946\n",
      "    Fold 4/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6059\n",
      "    Fold 5/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.5981\n",
      "  Mean F1 Score for 5 features: 0.6124 (±0.0301)\n",
      "  Testing with feature selection: 10\n",
      "    Fold 1/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.7296\n",
      "    Fold 2/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 200, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.6732\n",
      "    Fold 3/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.7214\n",
      "    Fold 4/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.6726\n",
      "    Fold 5/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6648\n",
      "  Mean F1 Score for 10 features: 0.6923 (±0.0274)\n",
      "  Testing with feature selection: 15\n",
      "    Fold 1/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6982\n",
      "    Fold 2/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6878\n",
      "    Fold 3/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.7220\n",
      "    Fold 4/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.7026\n",
      "    Fold 5/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6689\n",
      "  Mean F1 Score for 15 features: 0.6959 (±0.0174)\n",
      "  Testing with feature selection: 20\n",
      "    Fold 1/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6982\n",
      "    Fold 2/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6878\n",
      "    Fold 3/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 1.0}\n",
      "      Validation F1 Score: 0.7220\n",
      "    Fold 4/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.7026\n",
      "    Fold 5/5\n",
      "      Best params: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.6689\n",
      "  Mean F1 Score for 20 features: 0.6959 (±0.0174)\n",
      "  Testing with feature selection: all\n",
      "    Fold 1/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.8767\n",
      "    Fold 2/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.8756\n",
      "    Fold 3/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.8763\n",
      "    Fold 4/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.8829\n",
      "    Fold 5/5\n",
      "      Best params: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "      Validation F1 Score: 0.8792\n",
      "  Mean F1 Score for all features: 0.8781 (±0.0027)\n",
      "\n",
      "Best configuration for xgboost:\n",
      "  Number of features: all\n",
      "  Best parameters: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
      "  Best CV F1 Score: 0.8781\n",
      "  Most important features: ProductType_Devices, ProductType_Drugs, ProductType_Food/Cosmetics, ProductType_Veterinary, Status_Terminated\n",
      "\n",
      "Training and evaluating mlp...\n",
      "  Testing with feature selection: 5\n",
      "    Fold 1/5\n",
      "      Best params: {'model__activation': 'relu', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50,), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7158\n",
      "    Fold 2/5\n",
      "      Best params: {'model__activation': 'relu', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.6718\n",
      "    Fold 3/5\n",
      "      Best params: {'model__activation': 'relu', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7048\n",
      "    Fold 4/5\n",
      "      Best params: {'model__activation': 'relu', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.6838\n",
      "    Fold 5/5\n",
      "      Best params: {'model__activation': 'relu', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (100,), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.6746\n",
      "  Mean F1 Score for 5 features: 0.6902 (±0.0173)\n",
      "  Testing with feature selection: 10\n",
      "    Fold 1/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7185\n",
      "    Fold 2/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7444\n",
      "    Fold 3/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7519\n",
      "    Fold 4/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7397\n",
      "    Fold 5/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7267\n",
      "  Mean F1 Score for 10 features: 0.7362 (±0.0121)\n",
      "  Testing with feature selection: 15\n",
      "    Fold 1/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7743\n",
      "    Fold 2/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7670\n",
      "    Fold 3/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7824\n",
      "    Fold 4/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7995\n",
      "    Fold 5/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.7810\n",
      "  Mean F1 Score for 15 features: 0.7808 (±0.0108)\n",
      "  Testing with feature selection: 20\n",
      "    Fold 1/5\n",
      "      Best params: {'model__activation': 'tanh', 'model__alpha': 0.001, 'model__hidden_layer_sizes': (50, 50), 'model__learning_rate': 'constant'}\n",
      "      Validation F1 Score: 0.8361\n",
      "    Fold 2/5\n"
     ]
    }
   ],
   "source": [
    "# # Used ChatGPT to create this code that loops through a set of machine learning models\n",
    "for model_name, model_config in models.items():\n",
    "    print(f\"\\nTraining and evaluating {model_name}...\")\n",
    "    \n",
    "    model_best_score = 0\n",
    "    model_best_config = None\n",
    "    model_best_features = None\n",
    "    \n",
    "    # Iterate through different feature selection options\n",
    "    for n_features in n_features_options:\n",
    "        print(f\"  Testing with feature selection: {n_features}\")\n",
    "        \n",
    "        # Scores across folds\n",
    "        fold_scores = []\n",
    "        fold_feature_importances = []\n",
    "        \n",
    "        # Iterate through each fold\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train_encoded)):\n",
    "            print(f\"    Fold {fold_idx+1}/{n_cv_folds}\")\n",
    "            \n",
    "            # Split data into training and validation sets for this fold\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "            \n",
    "            # Apply SMOTE only to the training portion of this fold\n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_fold_train_resampled, y_fold_train_resampled = sm.fit_resample(X_fold_train, y_fold_train)\n",
    "            \n",
    "            # Define steps for the pipeline, conditionally including scaling\n",
    "            steps = []\n",
    "            \n",
    "            # Add scaling if needed\n",
    "            if model_config['needs_scaling']:\n",
    "                steps.append(('scaler', StandardScaler()))\n",
    "            \n",
    "            # Add feature selection unless n_features is 'all'\n",
    "            if n_features != 'all':\n",
    "                if model_config['feature_selector'] == SelectKBest:\n",
    "                    steps.append(('feature_selection', SelectKBest(f_classif, k=n_features)))\n",
    "                else:\n",
    "                    steps.append(('feature_selection', model_config['feature_selector'](model_config['model'], max_features=n_features)))\n",
    "            \n",
    "            # Add the model\n",
    "            steps.append(('model', model_config['model']))\n",
    "            \n",
    "            # Create pipeline\n",
    "            pipeline = Pipeline(steps)\n",
    "            \n",
    "            # Create grid search for hyperparameter tuning\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline,\n",
    "                param_grid=model_config['param_grid'],\n",
    "                cv=3,  # Use 3-fold CV for hyperparameter tuning within this fold\n",
    "                scoring='f1_weighted',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Train with grid search\n",
    "            grid_search.fit(X_fold_train_resampled, y_fold_train_resampled)\n",
    "            \n",
    "            # Get best model\n",
    "            best_fold_model = grid_search.best_estimator_\n",
    "            \n",
    "            # Predict on validation fold\n",
    "            y_fold_pred = best_fold_model.predict(X_fold_val)\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            fold_f1_score = f1_score(y_fold_val, y_fold_pred, average='weighted')\n",
    "            fold_scores.append(fold_f1_score)\n",
    "            \n",
    "            # Track feature importance for this fold\n",
    "            if n_features != 'all' and 'feature_selection' in best_fold_model.named_steps:\n",
    "                feature_selector = best_fold_model.named_steps['feature_selection']\n",
    "                if hasattr(feature_selector, 'get_support'):\n",
    "                    support = feature_selector.get_support()\n",
    "                    # Track which features were selected\n",
    "                    selected_features = X_train.columns[support]\n",
    "                    fold_feature_importances.append(selected_features)\n",
    "            \n",
    "            print(f\"      Best params: {grid_search.best_params_}\")\n",
    "            print(f\"      Validation F1 Score: {fold_f1_score:.4f}\")\n",
    "        \n",
    "        # Calculate mean score across folds\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        print(f\"  Mean F1 Score for {n_features} features: {mean_score:.4f} (±{std_score:.4f})\")\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name].append({\n",
    "            'n_features': n_features,\n",
    "            'mean_f1': mean_score,\n",
    "            'std_f1': std_score,\n",
    "            'fold_scores': fold_scores\n",
    "        })\n",
    "        \n",
    "        # Update best configuration if this is better\n",
    "        if mean_score > model_best_score:\n",
    "            model_best_score = mean_score\n",
    "            model_best_config = {\n",
    "                'n_features': n_features,\n",
    "                'parameters': grid_search.best_params_\n",
    "            }\n",
    "            \n",
    "            # Track most frequently selected features\n",
    "            if n_features != 'all' and fold_feature_importances:\n",
    "                # Count feature occurrences across folds\n",
    "                feature_counts = {}\n",
    "                for features in fold_feature_importances:\n",
    "                    for feature in features:\n",
    "                        if feature in feature_counts:\n",
    "                            feature_counts[feature] += 1\n",
    "                        else:\n",
    "                            feature_counts[feature] = 1\n",
    "                \n",
    "                # Sort by frequency\n",
    "                sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "                model_best_features = [f[0] for f in sorted_features[:n_features]]\n",
    "                \n",
    "                # Update feature importance tracking\n",
    "                for feature, count in feature_counts.items():\n",
    "                    feature_importance.loc[feature, model_name] += count\n",
    "    \n",
    "    # Store the best configuration for this model\n",
    "    best_configs[model_name] = {\n",
    "        'config': model_best_config,\n",
    "        'best_score': model_best_score,\n",
    "        'best_features': model_best_features\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nBest configuration for {model_name}:\")\n",
    "    print(f\"  Number of features: {model_best_config['n_features']}\")\n",
    "    print(f\"  Best parameters: {model_best_config['parameters']}\")\n",
    "    print(f\"  Best CV F1 Score: {model_best_score:.4f}\")\n",
    "    \n",
    "    if model_best_features:\n",
    "        print(f\"  Most important features: {', '.join(model_best_features[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d389b7-038e-4659-98bb-9cc1081552f9",
   "metadata": {},
   "source": [
    "Normalize feature importance by number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23699848-1c8f-4eaf-a0d5-6017d1b240f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each feature count by number of CV folds\n",
    "feature_importance = feature_importance / n_cv_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d284ae7-d065-434f-a687-3b4c4b1fc2d3",
   "metadata": {},
   "source": [
    "Find overall best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7360039-984b-4512-aebc-b498a3a6e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find model with highest F1 score\n",
    "best_model_name = max(best_configs, key=lambda k: best_configs[k]['best_score'])\n",
    "best_model_score = best_configs[best_model_name]['best_score']\n",
    "best_model_config = best_configs[best_model_name]['config']\n",
    "best_model_features = best_configs[best_model_name]['best_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec84a3-593b-4980-b734-5cefdff1ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nOverall best model: {best_model_name}\")\n",
    "print(f\"Best CV F1 Score: {best_model_score:.4f}\")\n",
    "print(f\"Best configuration: {best_model_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b064fc4-e553-4216-83ff-f176fd4c2750",
   "metadata": {},
   "source": [
    "Visualize model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e5176-3476-4701-b54d-253e7dfa467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of model and F1 scores to compare\n",
    "model_comparison = pd.DataFrame([\n",
    "    {'Model': model_name, 'Best F1 Score': config['best_score']}\n",
    "    for model_name, config in best_configs.items()\n",
    "])\n",
    "model_comparison = model_comparison.sort_values('Best F1 Score', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Model', y='Best F1 Score', data=model_comparison)\n",
    "plt.title('Model Comparison - Best CV F1 Scores')\n",
    "plt.ylim(0, 1.0)\n",
    "\n",
    "# Add score labels\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(f\"{p.get_height():.4f}\", (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'results/{dataset_type}/model_comparison_cv.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510cfcd-8d8e-435f-89ea-b56540339e07",
   "metadata": {},
   "source": [
    "# Final Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0b15f-3a3f-4790-a44c-179b54d62a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model configuration\n",
    "best_config = best_configs[best_model_name]['config']\n",
    "best_params = {k.replace('model__', ''): v for k, v in best_config['parameters'].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06202028-be9f-4d15-abdc-dbdcc6646dd1",
   "metadata": {},
   "source": [
    "## Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d57a4-ad6a-4766-8f01-301a45f572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to full training set\n",
    "print(\"Applying SMOTE to full training set...\")\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train_encoded)\n",
    "\n",
    "print(f\"{best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ef540-e7d9-4110-a3ef-d643001b5425",
   "metadata": {},
   "source": [
    "#### Create final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b02ad-ef59-439f-9518-a23726d9909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list steps for pipeline\n",
    "final_steps = []\n",
    "\n",
    "# Scaling\n",
    "if models[best_model_name]['needs_scaling']:\n",
    "    final_steps.append(('scaler', StandardScaler()))\n",
    "\n",
    "# Feature selection\n",
    "if best_config['n_features'] != 'all':\n",
    "    if models[best_model_name]['feature_selector'] == SelectKBest:\n",
    "        final_steps.append(('feature_selection', SelectKBest(f_classif, k=best_config['n_features'])))\n",
    "    else:\n",
    "        final_steps.append(('feature_selection', models[best_model_name]['feature_selector'](\n",
    "            models[best_model_name]['model'], max_features=best_config['n_features']\n",
    "        )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d079d59-ab9f-459c-a554-de0d06898741",
   "metadata": {},
   "source": [
    "#### Create the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361b211-05c1-4b33-af6e-b3c27f7c4723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure new instance for best model\n",
    "model_instance = models[best_model_name]['model'].__class__(**best_params)\n",
    "final_steps.append(('model', model_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae1364-0798-49d4-90dd-af96df8376fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build and train final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da8a89-979c-4ec5-92ba-53d33ca57175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with preprocessing and selection steps on balanced data\n",
    "final_pipeline = Pipeline(final_steps)\n",
    "final_pipeline.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8707ea-2203-4246-a75b-800b0b9f2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "os.makedirs(f'results/{dataset_type}/final_models', exist_ok=True)\n",
    "joblib.dump(final_pipeline, f'results/{dataset_type}/final_models/{best_model_name}_final_model.joblib')\n",
    "joblib.dump(le, f'results/{dataset_type}/final_models/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e6483-c6b4-414a-a731-6a0ae41eb236",
   "metadata": {},
   "source": [
    "## Final Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb9d42-f41b-4eb5-b88c-2c8ec96e7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = final_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4d278-41c8-4200-a161-cc9410e6293c",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f95a2a-0af1-4f89-af20-889001d29dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_encoded, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb5595-bc85-49f6-94f0-a611311ece4f",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9ea43-d103-4856-a724-9838bcb31627",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f\"Final {best_model_name.capitalize()} Model - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'results/{dataset_type}/final_model_confusion_matrix.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94d1c6-827f-40e2-ba91-3ac75065250d",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8e73a-af80-41ef-adf1-16d839233609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "precision = precision_score(y_test_encoded, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_encoded, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_encoded, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nFinal Model Test Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11de1fa-42a8-4068-9430-1d143de985fd",
   "metadata": {},
   "source": [
    "#### Class-specific Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7edfd2-8a48-4a01-8718-b487c3e537ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each class in target variable and compute Precision, Recall, F1 score\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_precision = precision_score(y_test_encoded, y_pred, labels=[i], average=None)[0]\n",
    "    class_recall = recall_score(y_test_encoded, y_pred, labels=[i], average=None)[0]\n",
    "    class_f1 = f1_score(y_test_encoded, y_pred, labels=[i], average=None)[0]\n",
    "    \n",
    "    print(f\"{class_name}:\")\n",
    "    print(f\"  Precision: {class_precision:.4f}\")\n",
    "    print(f\"  Recall: {class_recall:.4f}\")\n",
    "    print(f\"  F1 Score: {class_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e1a7e-3a96-4580-8eec-ae8594120de1",
   "metadata": {},
   "source": [
    "#### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39e2f6-4f34-4ff8-9738-ea1a351623f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If model supports predict_proba, then get predicted variable for each class\n",
    "if hasattr(final_pipeline, 'predict_proba'):\n",
    "    y_proba = final_pipeline.predict_proba(X_test)\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # For each class\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        fpr, tpr, _ = roc_curve(y_test_encoded == i, y_proba[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{class_name} (area = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves - Final {best_model_name.capitalize()} Model')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'results/{dataset_type}/final_model_roc_curves.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc65fd2-2d22-455c-9873-36bb316347af",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df52d9-3767-4aa2-bb59-77a9a800f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used ChatGPT to streamline the analysis and visualization of feature importance\n",
    "if hasattr(final_pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    # For tree-based models that have feature_importances_\n",
    "    if 'feature_selection' in final_pipeline.named_steps:\n",
    "        # Get selected features\n",
    "        mask = final_pipeline.named_steps['feature_selection'].get_support()\n",
    "        selected_features = X_train.columns[mask]\n",
    "        importances = final_pipeline.named_steps['model'].feature_importances_\n",
    "        \n",
    "        # Create DataFrame for visualization\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': selected_features,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "    else:\n",
    "        # All features were used\n",
    "        importances = final_pipeline.named_steps['model'].feature_importances_\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 most important features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20), palette='viridis')\n",
    "    plt.title(f\"Feature Importance - Final {best_model_name.capitalize()} Model\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{dataset_type}/final_model_feature_importance.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    importance_df.to_csv(f'results/{dataset_type}/final_model_feature_importance.csv', index=False)\n",
    "elif hasattr(final_pipeline.named_steps['model'], 'coef_'):\n",
    "    # For models like Logistic Regression that have coefficients\n",
    "    if 'feature_selection' in final_pipeline.named_steps:\n",
    "        # Get selected features\n",
    "        mask = final_pipeline.named_steps['feature_selection'].get_support()\n",
    "        selected_features = X_train.columns[mask]\n",
    "        \n",
    "        # For multi-class, take mean absolute coefficient values\n",
    "        coef = final_pipeline.named_steps['model'].coef_\n",
    "        if coef.ndim > 1:\n",
    "            importances = np.mean(np.abs(coef), axis=0)\n",
    "        else:\n",
    "            importances = np.abs(coef)\n",
    "        \n",
    "        # Create DataFrame for visualization\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': selected_features,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "    else:\n",
    "        # All features were used\n",
    "        coef = final_pipeline.named_steps['model'].coef_\n",
    "        if coef.ndim > 1:\n",
    "            importances = np.mean(np.abs(coef), axis=0)\n",
    "        else:\n",
    "            importances = np.abs(coef)\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 most important features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20), palette='viridis')\n",
    "    plt.title(f\"Feature Importance - Final {best_model_name.capitalize()} Model\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{dataset_type}/final_model_feature_importance.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    importance_df.to_csv(f'results/{dataset_type}/final_model_feature_importance.csv', index=False)\n",
    "else:\n",
    "    # Use the cross-validation feature importance tracking\n",
    "    print(\"\\nFeature importance based on selection frequency during cross-validation:\")\n",
    "    \n",
    "    # Normalize by model count\n",
    "    avg_importance = feature_importance.mean(axis=1)\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_importance.index,\n",
    "        'Selection Frequency': avg_importance\n",
    "    }).sort_values('Selection Frequency', ascending=False)\n",
    "    \n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Selection Frequency', y='Feature', data=importance_df.head(20), palette='viridis')\n",
    "    plt.title(\"Feature Selection Frequency Across Models\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{dataset_type}/feature_selection_frequency.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    importance_df.to_csv(f'results/{dataset_type}/feature_selection_frequency.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fa176-5872-42a0-a813-4d7d5b0b538f",
   "metadata": {},
   "source": [
    "# Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d18c049-a635-4619-9060-2a4542e296e9",
   "metadata": {},
   "source": [
    "#### Class-specific test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebaeaf4-1538-4ca7-b7f1-83ea21f69774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class-specific performance DataFrame\n",
    "class_report = classification_report(y_test_encoded, y_pred, target_names=class_names, output_dict=True)\n",
    "class_df = pd.DataFrame()\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_df.loc[class_name, 'f1-score'] = class_report[class_name]['f1-score']\n",
    "    class_df.loc[class_name, 'precision'] = class_report[class_name]['precision']\n",
    "    class_df.loc[class_name, 'recall'] = class_report[class_name]['recall']\n",
    "\n",
    "class_df = class_df.sort_values('f1-score', ascending=False)\n",
    "print(class_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a449f48-5bc6-4687-9ed5-ceadeb3395e3",
   "metadata": {},
   "source": [
    "#### Best and Worst Performing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be7206-de6c-409e-bc6e-e880e843278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first (best) and last (worst) index\n",
    "best_class = class_df.index[0]\n",
    "worst_class = class_df.index[-1]\n",
    "\n",
    "print(f\"\\nBest performing class: {best_class} (F1: {class_df.loc[best_class, 'f1-score']:.4f})\")\n",
    "print(f\"Worst performing class: {worst_class} (F1: {class_df.loc[worst_class, 'f1-score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411399e-7fe4-4d0b-a6cb-f09eb66b38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save Summary into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6babc8-5c9b-441e-812e-06c953cb556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary dictionary\n",
    "summary = {\n",
    "    'dataset_type': dataset_type,\n",
    "    'best_model': best_model_name,\n",
    "    'best_cv_f1': float(best_model_score),\n",
    "    'test_f1': float(f1),\n",
    "    'best_class': best_class,\n",
    "    'best_class_f1': float(class_df.loc[best_class, 'f1-score']),\n",
    "    'worst_class': worst_class,\n",
    "    'worst_class_f1': float(class_df.loc[worst_class, 'f1-score']),\n",
    "    'best_features': best_model_features[:10] if best_model_features else None,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open(f'results/{dataset_type}/modeling_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c1a9a-43cc-4f2d-be48-69d5d5ee47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nModeling process completed for {dataset_type} dataset.\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Best CV F1 Score: {best_model_score:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "if best_model_features:\n",
    "    print(f\"Top 5 most important features: {', '.join(best_model_features[:5])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
