{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6cdfc50-7af3-40af-b21e-591835feca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling notebook enhanced by https://claude.ai/\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import (classification_report, accuracy_score, \n",
    "                            confusion_matrix, ConfusionMatrixDisplay, \n",
    "                            roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76d36e6-3194-4043-959b-9fddd40a804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for saving results\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('results/baseline', exist_ok=True)\n",
    "os.makedirs('results/hybrid', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e41a664-59cd-42c9-a797-10f1fc2bff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eac42f7-66b1-4863-a275-ded6f934c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "    MODELING PIPELINE FOR HYBRID DATASET\n",
      "================================================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "1. EXPLORATORY DATA ANALYSIS\n",
      "==================================================\n",
      "Successfully loaded hybrid datasets:\n",
      "Training shape: (76065, 330)\n",
      "Testing shape: (19017, 330)\n",
      "\n",
      "Training Dataset Overview:\n",
      "Columns: ['Month_sin', 'Month_cos', 'Day_sin', 'Day_cos', 'DayOfWeek_sin', 'DayOfWeek_cos', 'Years_Since_First', 'Is_US', 'ProductClassification_Class II', 'ProductClassification_Class III', 'ProductType_Devices', 'ProductType_Drugs', 'ProductType_Food/Cosmetics', 'ProductType_Tobacco', 'ProductType_Veterinary', 'Status_Ongoing', 'Status_Terminated', 'Business_Structure_Association', 'Business_Structure_Company', 'Business_Structure_Corporation', 'Business_Structure_Inc', 'Business_Structure_LLC', 'Business_Structure_LLP', 'Business_Structure_LP', 'Business_Structure_Ltd', 'Business_Structure_Non-Profit', 'Business_Structure_Other', 'Business_Structure_PLC', 'Business_Structure_SA', 'text_svd_0', 'text_svd_1', 'text_svd_2', 'text_svd_3', 'text_svd_4', 'text_svd_5', 'text_svd_6', 'text_svd_7', 'text_svd_8', 'text_svd_9', 'text_svd_10', 'text_svd_11', 'text_svd_12', 'text_svd_13', 'text_svd_14', 'text_svd_15', 'text_svd_16', 'text_svd_17', 'text_svd_18', 'text_svd_19', 'text_svd_20', 'text_svd_21', 'text_svd_22', 'text_svd_23', 'text_svd_24', 'text_svd_25', 'text_svd_26', 'text_svd_27', 'text_svd_28', 'text_svd_29', 'text_svd_30', 'text_svd_31', 'text_svd_32', 'text_svd_33', 'text_svd_34', 'text_svd_35', 'text_svd_36', 'text_svd_37', 'text_svd_38', 'text_svd_39', 'text_svd_40', 'text_svd_41', 'text_svd_42', 'text_svd_43', 'text_svd_44', 'text_svd_45', 'text_svd_46', 'text_svd_47', 'text_svd_48', 'text_svd_49', 'text_svd_50', 'text_svd_51', 'text_svd_52', 'text_svd_53', 'text_svd_54', 'text_svd_55', 'text_svd_56', 'text_svd_57', 'text_svd_58', 'text_svd_59', 'text_svd_60', 'text_svd_61', 'text_svd_62', 'text_svd_63', 'text_svd_64', 'text_svd_65', 'text_svd_66', 'text_svd_67', 'text_svd_68', 'text_svd_69', 'text_svd_70', 'text_svd_71', 'text_svd_72', 'text_svd_73', 'text_svd_74', 'text_svd_75', 'text_svd_76', 'text_svd_77', 'text_svd_78', 'text_svd_79', 'text_svd_80', 'text_svd_81', 'text_svd_82', 'text_svd_83', 'text_svd_84', 'text_svd_85', 'text_svd_86', 'text_svd_87', 'text_svd_88', 'text_svd_89', 'text_svd_90', 'text_svd_91', 'text_svd_92', 'text_svd_93', 'text_svd_94', 'text_svd_95', 'text_svd_96', 'text_svd_97', 'text_svd_98', 'text_svd_99', 'text_svd_100', 'text_svd_101', 'text_svd_102', 'text_svd_103', 'text_svd_104', 'text_svd_105', 'text_svd_106', 'text_svd_107', 'text_svd_108', 'text_svd_109', 'text_svd_110', 'text_svd_111', 'text_svd_112', 'text_svd_113', 'text_svd_114', 'text_svd_115', 'text_svd_116', 'text_svd_117', 'text_svd_118', 'text_svd_119', 'text_svd_120', 'text_svd_121', 'text_svd_122', 'text_svd_123', 'text_svd_124', 'text_svd_125', 'text_svd_126', 'text_svd_127', 'text_svd_128', 'text_svd_129', 'text_svd_130', 'text_svd_131', 'text_svd_132', 'text_svd_133', 'text_svd_134', 'text_svd_135', 'text_svd_136', 'text_svd_137', 'text_svd_138', 'text_svd_139', 'text_svd_140', 'text_svd_141', 'text_svd_142', 'text_svd_143', 'text_svd_144', 'text_svd_145', 'text_svd_146', 'text_svd_147', 'text_svd_148', 'text_svd_149', 'text_svd_150', 'text_svd_151', 'text_svd_152', 'text_svd_153', 'text_svd_154', 'text_svd_155', 'text_svd_156', 'text_svd_157', 'text_svd_158', 'text_svd_159', 'text_svd_160', 'text_svd_161', 'text_svd_162', 'text_svd_163', 'text_svd_164', 'text_svd_165', 'text_svd_166', 'text_svd_167', 'text_svd_168', 'text_svd_169', 'text_svd_170', 'text_svd_171', 'text_svd_172', 'text_svd_173', 'text_svd_174', 'text_svd_175', 'text_svd_176', 'text_svd_177', 'text_svd_178', 'text_svd_179', 'text_svd_180', 'text_svd_181', 'text_svd_182', 'text_svd_183', 'text_svd_184', 'text_svd_185', 'text_svd_186', 'text_svd_187', 'text_svd_188', 'text_svd_189', 'text_svd_190', 'text_svd_191', 'text_svd_192', 'text_svd_193', 'text_svd_194', 'text_svd_195', 'text_svd_196', 'text_svd_197', 'text_svd_198', 'text_svd_199', 'text_svd_200', 'text_svd_201', 'text_svd_202', 'text_svd_203', 'text_svd_204', 'text_svd_205', 'text_svd_206', 'text_svd_207', 'text_svd_208', 'text_svd_209', 'text_svd_210', 'text_svd_211', 'text_svd_212', 'text_svd_213', 'text_svd_214', 'text_svd_215', 'text_svd_216', 'text_svd_217', 'text_svd_218', 'text_svd_219', 'text_svd_220', 'text_svd_221', 'text_svd_222', 'text_svd_223', 'text_svd_224', 'text_svd_225', 'text_svd_226', 'text_svd_227', 'text_svd_228', 'text_svd_229', 'text_svd_230', 'text_svd_231', 'text_svd_232', 'text_svd_233', 'text_svd_234', 'text_svd_235', 'text_svd_236', 'text_svd_237', 'text_svd_238', 'text_svd_239', 'text_svd_240', 'text_svd_241', 'text_svd_242', 'text_svd_243', 'text_svd_244', 'text_svd_245', 'text_svd_246', 'text_svd_247', 'text_svd_248', 'text_svd_249', 'text_svd_250', 'text_svd_251', 'text_svd_252', 'text_svd_253', 'text_svd_254', 'text_svd_255', 'text_svd_256', 'text_svd_257', 'text_svd_258', 'text_svd_259', 'text_svd_260', 'text_svd_261', 'text_svd_262', 'text_svd_263', 'text_svd_264', 'text_svd_265', 'text_svd_266', 'text_svd_267', 'text_svd_268', 'text_svd_269', 'text_svd_270', 'text_svd_271', 'text_svd_272', 'text_svd_273', 'text_svd_274', 'text_svd_275', 'text_svd_276', 'text_svd_277', 'text_svd_278', 'text_svd_279', 'text_svd_280', 'text_svd_281', 'text_svd_282', 'text_svd_283', 'text_svd_284', 'text_svd_285', 'text_svd_286', 'text_svd_287', 'text_svd_288', 'text_svd_289', 'text_svd_290', 'text_svd_291', 'text_svd_292', 'text_svd_293', 'text_svd_294', 'text_svd_295', 'text_svd_296', 'text_svd_297', 'text_svd_298', 'text_svd_299', 'Event Classification']\n",
      "\n",
      "Data Types:\n",
      "Month_sin               float64\n",
      "Month_cos               float64\n",
      "Day_sin                 float64\n",
      "Day_cos                 float64\n",
      "DayOfWeek_sin           float64\n",
      "                         ...   \n",
      "text_svd_296            float64\n",
      "text_svd_297            float64\n",
      "text_svd_298            float64\n",
      "text_svd_299            float64\n",
      "Event Classification     object\n",
      "Length: 330, dtype: object\n",
      "\n",
      "Target Distribution:\n",
      "       Class  Proportion\n",
      "0   Class II    0.708065\n",
      "1    Class I    0.211516\n",
      "2  Class III    0.080418\n"
     ]
    }
   ],
   "source": [
    "dataset_type = 'hybrid'\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"    MODELING PIPELINE FOR {dataset_type.upper()} DATASET\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Step 1: Exploratory Data Analysis (EDA)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"1. EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the dataset\n",
    "train_path = f'/Users/x/Downloads/data2/train_hybrid.csv'\n",
    "test_path = f'/Users/x/Downloads/data2/test_hybrid.csv'\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    print(f\"Successfully loaded {dataset_type} datasets:\")\n",
    "    print(f\"Training shape: {train_df.shape}\")\n",
    "    print(f\"Testing shape: {test_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find {dataset_type} dataset files. Please check file paths.\")\n",
    "else:\n",
    "    # Basic dataset information\n",
    "    print(\"\\nTraining Dataset Overview:\")\n",
    "    print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "    print(\"\\nData Types:\")\n",
    "    print(train_df.dtypes)\n",
    "\n",
    "    # Target distribution\n",
    "    target_col = 'Event Classification'\n",
    "    target_dist = train_df[target_col].value_counts(normalize=True).reset_index()\n",
    "    target_dist.columns = ['Class', 'Proportion']\n",
    "    print(\"\\nTarget Distribution:\")\n",
    "    print(target_dist)\n",
    "\n",
    "    # Visualize target distribution\n",
    "    os.makedirs(f'results/{dataset_type}', exist_ok=True)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Class', y='Proportion', data=target_dist)\n",
    "    plt.title(f'Target Distribution - {dataset_type.capitalize()} Dataset')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.savefig(f'results/{dataset_type}/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7631079-1e89-49d4-89da-dcbd13270099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "2. DATA CLEANING VALIDATION\n",
      "==================================================\n",
      "\n",
      "Missing values in training data:\n",
      "No missing values found\n",
      "\n",
      "==================================================\n",
      "3. DATA PREPARATION\n",
      "==================================================\n",
      "Target Classes: ['Class I' 'Class II' 'Class III']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Cleaning (Validation)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"2. DATA CLEANING VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = train_df.isnull().sum()\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values found\")\n",
    "\n",
    "# Step 3: Data Preparation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"3. DATA PREPARATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X_train = train_df.drop(target_col, axis=1)\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df.drop(target_col, axis=1)\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Ensure test data has the same columns as train data\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for col in missing_cols:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "class_names = le.classes_\n",
    "print(f\"Target Classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "811fb9c2-c380-4553-a0df-0741a139aabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "4. TRAIN-TEST SPLIT VALIDATION\n",
      "==================================================\n",
      "Training set size: 76065\n",
      "Test set size: 19017\n",
      "Test set proportion: 20.00%\n",
      "\n",
      "Training class distribution:\n",
      "1    0.708065\n",
      "0    0.211516\n",
      "2    0.080418\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test class distribution:\n",
      "1    0.708103\n",
      "0    0.211495\n",
      "2    0.080402\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "5. FEATURE ENGINEERING VALIDATION\n",
      "==================================================\n",
      "Number of features: 329\n",
      "Temporal features: 7\n",
      "Text-derived features: 300\n",
      "Categorical features: 21\n",
      "\n",
      "==================================================\n",
      "6. PRE-PROCESSED DATASET VALIDATION\n",
      "==================================================\n",
      "Checking for infinity or NaN values...\n",
      "No infinity or NaN values found.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train-Test Split Validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"4. TRAIN-TEST SPLIT VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# The split was done in preprocessing, but validate proportions\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "print(\"Test set proportion: {:.2f}%\".format(100 * X_test.shape[0] / (X_train.shape[0] + X_test.shape[0])))\n",
    "\n",
    "print(\"\\nTraining class distribution:\")\n",
    "print(pd.Series(y_train_encoded).value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(pd.Series(y_test_encoded).value_counts(normalize=True))\n",
    "\n",
    "# Step 5: Feature Engineering Validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"5. FEATURE ENGINEERING VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display number of features\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "# Display feature categories\n",
    "temporal_features = [col for col in X_train.columns if any(x in col for x in ['Month', 'Day', 'Year', 'Week'])]\n",
    "text_features = [col for col in X_train.columns if 'text_svd_' in col]\n",
    "categorical_features = [col for col in X_train.columns if any(x in col for x in ['Classification', 'Type', 'Status', 'Structure'])]\n",
    "\n",
    "print(f\"Temporal features: {len(temporal_features)}\")\n",
    "print(f\"Text-derived features: {len(text_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Step 6: Pre-processed Dataset Validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. PRE-PROCESSED DATASET VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(\"Checking for infinity or NaN values...\")\n",
    "inf_count = np.isinf(X_train.values).sum()\n",
    "nan_count = np.isnan(X_train.values).sum()\n",
    "\n",
    "if inf_count > 0 or nan_count > 0:\n",
    "    print(f\"Warning: Found {inf_count} infinity values and {nan_count} NaN values\")\n",
    "    # Handle inf/nan values if necessary\n",
    "    X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "else:\n",
    "    print(\"No infinity or NaN values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bd9b59f-54b5-4c09-b4ac-8693669819a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import sem, t\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3297049-d61a-4eb2-bb91-f3236d3b0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with L1 and L2 regularization\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(solver='liblinear', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Hyperparameters for both L1 and L2\n",
    "param_grid = {\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(logreg_pipeline, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1eee03-0a89-4de1-8e2c-a4a69881360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc = roc_auc_score(y_test_encoded, y_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test_encoded, y_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682903c-0692-4efc-a795-227fc4400193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and coefficients\n",
    "feature_names = X_train.columns\n",
    "coefficients = best_model.named_steps['log_reg'].coef_[0]\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Plot the top 20 most important features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=coef_df.head(20), x='Abs_Coefficient', y='Feature', palette='coolwarm')\n",
    "plt.title(\"Top 20 Important Features (Logistic Regression Coefficients)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34acc219-cd3f-4be2-a3b2-b314cf21da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature variance\n",
    "variance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Variance': X_train.var()\n",
    "}).sort_values(by='Variance', ascending=False)\n",
    "\n",
    "# Plot top 20 by variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=variance_df.head(20), x='Variance', y='Feature', palette='viridis')\n",
    "plt.title(\"Top 20 Features by Variance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04cb39-5cde-483c-b9fb-a9b404935d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store bootstrap metrics\n",
    "boot_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_iterations = 1000\n",
    "random_state = 42\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Resample predictions\n",
    "    indices = resample(np.arange(len(y_test_encoded)), replace=True, random_state=random_state + i)\n",
    "    y_true_sample = y_test_encoded[indices]\n",
    "    y_pred_sample = y_pred[indices]\n",
    "\n",
    "    # Append scores\n",
    "    boot_metrics['accuracy'].append(accuracy_score(y_true_sample, y_pred_sample))\n",
    "    boot_metrics['precision'].append(precision_score(y_true_sample, y_pred_sample))\n",
    "    boot_metrics['recall'].append(recall_score(y_true_sample, y_pred_sample))\n",
    "    boot_metrics['f1'].append(f1_score(y_true_sample, y_pred_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14a844-0ca2-4ee7-a44d-8d476f2068c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table\n",
    "ci_table = pd.DataFrame(columns=['Metric', 'Mean', '95% CI Lower', '95% CI Upper'])\n",
    "\n",
    "for metric in boot_metrics:\n",
    "    scores = boot_metrics[metric]\n",
    "    mean = np.mean(scores)\n",
    "    lower = np.percentile(scores, 2.5)\n",
    "    upper = np.percentile(scores, 97.5)\n",
    "    ci_table = ci_table.append({\n",
    "        'Metric': metric.capitalize(),\n",
    "        'Mean': round(mean, 4),\n",
    "        '95% CI Lower': round(lower, 4),\n",
    "        '95% CI Upper': round(upper, 4)\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nConfidence Intervals (95%) for Test Set Metrics:\")\n",
    "print(ci_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d6fd9-b62a-4e49-a235-22edc203b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confidence intervals\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(ci_table['Metric'], ci_table['Mean'],\n",
    "             yerr=[ci_table['Mean'] - ci_table['95% CI Lower'], ci_table['95% CI Upper'] - ci_table['Mean']],\n",
    "             fmt='o', capsize=5, color='blue', ecolor='gray', elinewidth=3)\n",
    "\n",
    "plt.title(\"Model Metrics with 95% Confidence Intervals\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4f23f-3c49-47d7-9062-a3edc035bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Grid search\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_dt.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Best model\n",
    "best_dt = grid_dt.best_estimator_\n",
    "print(\"\\nBest Decision Tree Parameters:\")\n",
    "print(grid_dt.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20184052-e677-4cc5-b9d9-ad4fe5e2aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_dt, target_names=class_names))\n",
    "\n",
    "# Confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(best_dt, X_test, y_test_encoded, display_labels=class_names, cmap='Blues')\n",
    "plt.title(\"Decision Tree - Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de4869-718a-4968-a17e-cb92581f8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_dt = best_dt.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create dataframe and sort\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances_dt})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(15)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
    "plt.title(\"Top 15 Feature Importances - Decision Tree\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac11072a-2cbd-402c-a1de-9fc15205f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap function\n",
    "def bootstrap_metrics(y_true, y_pred, n_bootstraps=1000, alpha=0.95):\n",
    "    np.random.seed(42)\n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': []\n",
    "    }\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = resample(range(len(y_true)))\n",
    "        y_true_sample = np.array(y_true)[indices]\n",
    "        y_pred_sample = np.array(y_pred)[indices]\n",
    "        \n",
    "        metrics['accuracy'].append(accuracy_score(y_true_sample, y_pred_sample))\n",
    "        metrics['precision'].append(precision_score(y_true_sample, y_pred_sample, average='weighted', zero_division=0))\n",
    "        metrics['recall'].append(recall_score(y_true_sample, y_pred_sample, average='weighted'))\n",
    "        metrics['f1'].append(f1_score(y_true_sample, y_pred_sample, average='weighted'))\n",
    "\n",
    "    # Calculate CIs\n",
    "    results = {}\n",
    "    for metric_name, values in metrics.items():\n",
    "        lower = np.percentile(values, (1 - alpha) / 2 * 100)\n",
    "        upper = np.percentile(values, (1 + alpha) / 2 * 100)\n",
    "        mean = np.mean(values)\n",
    "        results[metric_name] = (mean, lower, upper)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Get confidence intervals\n",
    "dt_ci = bootstrap_metrics(y_test_encoded, y_pred_dt)\n",
    "\n",
    "# Display nicely as table\n",
    "ci_df = pd.DataFrame.from_dict(dt_ci, orient='index', columns=['Mean', 'Lower 95% CI', 'Upper 95% CI'])\n",
    "ci_df.index = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "print(\"\\nDecision Tree Confidence Intervals (95%):\")\n",
    "print(ci_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcef80-fafc-4762-9d34-95e22267a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression setup\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# Grid for both L1 and L2 penalties\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_logreg = GridSearchCV(logreg, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_logreg.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Best model\n",
    "best_logreg = grid_logreg.best_estimator_\n",
    "print(f\"\\nBest Logistic Regression Parameters: {grid_logreg.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4526cd-d3a3-4a46-b888-1e2fa70b16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_logreg = best_logreg.predict(X_test)\n",
    "\n",
    "# Report\n",
    "print(\"\\nClassification Report (Logistic Regression):\")\n",
    "print(classification_report(y_test_encoded, y_pred_logreg, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_logreg = confusion_matrix(y_test_encoded, y_pred_logreg)\n",
    "sns.heatmap(conf_matrix_logreg, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f0b3b-bcb8-485c-a27c-de3b166b6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients from the best logistic regression model\n",
    "coefs = best_logreg.coef_[0]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame of feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefs,\n",
    "    'Importance (Abs)': np.abs(coefs)\n",
    "}).sort_values(by='Importance (Abs)', ascending=False)\n",
    "\n",
    "# Plot top 20 most important features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance (Abs)', y='Feature', data=importance_df.head(20), palette='viridis')\n",
    "plt.title('Top 20 Important Features - Logistic Regression')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e6b3a-afd1-4cd9-8256-684f46893b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to plot feature importances\n",
    "def plot_feature_importance(importances, features, model_name, top_n=20):\n",
    "    fi = pd.Series(importances, index=features).sort_values(ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=fi.values, y=fi.index, palette=\"viridis\")\n",
    "    plt.title(f\"{model_name} - Top {top_n} Feature Importances\")\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Helper to compute and print mean accuracy with confidence interval\n",
    "def report_accuracy(fold_scores):\n",
    "    mean_acc = np.mean(fold_scores)\n",
    "    ci = sem(fold_scores) * t.ppf((1 + 0.95) / 2., len(fold_scores)-1)\n",
    "    print(f\"  Mean Accuracy: {mean_acc:.4f} ± {ci:.4f}\")\n",
    "    return mean_acc, ci\n",
    "\n",
    "# Setup\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=42)\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\\nEvaluating Model: {name}\\n{'='*50}\")\n",
    "    fold_scores = []\n",
    "    feature_counts = pd.Series(0, index=X_train.columns)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train_encoded), 1):\n",
    "        print(f\"  Fold {fold}/{n_folds}\")\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_tr_resampled, y_tr_resampled = sm.fit_resample(X_tr, y_tr)\n",
    "\n",
    "        # Feature selection\n",
    "        selector_model = model.__class__(**model.get_params())\n",
    "        selector_model.fit(X_tr_resampled, y_tr_resampled)\n",
    "        selector = SelectFromModel(selector_model, threshold='mean', prefit=True)\n",
    "        selected_features = X_train.columns[selector.get_support()]\n",
    "        feature_counts[selected_features] += 1\n",
    "\n",
    "        X_tr_sel = selector.transform(X_tr_resampled)\n",
    "        X_val_sel = selector.transform(X_val)\n",
    "\n",
    "        # Train final model on selected features\n",
    "        fitted_model = model.__class__(**model.get_params())\n",
    "        fitted_model.fit(X_tr_sel, y_tr_resampled)\n",
    "        preds = fitted_model.predict(X_val_sel)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        fold_scores.append(acc)\n",
    "\n",
    "    # Final report\n",
    "    mean_acc, ci = report_accuracy(fold_scores)\n",
    "\n",
    "    # Feature Importance Plot\n",
    "    final_selector_model = model.__class__(**model.get_params())\n",
    "    sm_full = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = sm_full.fit_resample(X_train[selected_features], y_train_encoded)\n",
    "    final_selector_model.fit(X_resampled, y_resampled)\n",
    "    plot_feature_importance(final_selector_model.feature_importances_, selected_features, name)\n",
    "\n",
    "    # Save results\n",
    "    model_results[name] = {\n",
    "        'fold_accuracies': fold_scores,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'confidence_interval': ci,\n",
    "        'feature_importance': feature_counts.sort_values(ascending=False)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974914b-0823-4b85-b02d-3834adaab26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train_encoded)\n",
    "print(f\"Best Parameters for RF: {grid_search_rf.best_params_}\")\n",
    "best_rf_model = grid_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89f0e4-e617-4255-b5b9-4387f6b9f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Hyperparameter Tuning\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(XGBClassifier(eval_metric='mlogloss', random_state=42), param_grid_xgb, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search_xgb.fit(X_train, y_train_encoded)\n",
    "print(f\"Best Parameters for XGBoost: {grid_search_xgb.best_params_}\")\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4af035-df8c-492b-967a-f856d28f7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Hyperparameter Tuning\n",
    "param_grid_cb = {\n",
    "    'iterations': [500, 1000],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'depth': [6, 10],\n",
    "    'l2_leaf_reg': [3, 5]\n",
    "}\n",
    "\n",
    "grid_search_cb = GridSearchCV(CatBoostClassifier(verbose=0, random_state=42), param_grid_cb, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search_cb.fit(X_train, y_train_encoded)\n",
    "print(f\"Best Parameters for CatBoost: {grid_search_cb.best_params_}\")\n",
    "best_cb_model = grid_search_cb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9615f-c3f9-4422-9da6-23f74a93a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare comparison data\n",
    "model_names = ['Random Forest', 'XGBoost', 'CatBoost']\n",
    "mean_accuracies = [model_results['Random Forest']['mean_accuracy'], \n",
    "                   model_results['XGBoost']['mean_accuracy'], \n",
    "                   model_results['CatBoost']['mean_accuracy']]\n",
    "confidence_intervals = [model_results['Random Forest']['confidence_interval'], \n",
    "                        model_results['XGBoost']['confidence_interval'], \n",
    "                        model_results['CatBoost']['confidence_interval']]\n",
    "\n",
    "# Plot the comparison chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(model_names, mean_accuracies, yerr=confidence_intervals, capsize=5, color=['blue', 'green', 'red'], alpha=0.7)\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Model Comparison with Confidence Intervals')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b95e7-5a83-4ff2-b966-b16f20d05a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model Evaluation\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "xgb_fold_scores = []\n",
    "xgb_feature_counts = pd.Series(0, index=X_train.columns)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train_encoded), 1):\n",
    "    print(f\"  Fold {fold}/{n_folds} - XGBoost\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_tr_resampled, y_tr_resampled = sm.fit_resample(X_tr, y_tr)\n",
    "\n",
    "    # Feature selection\n",
    "    selector_model = xgb_model.__class__(**xgb_model.get_params())\n",
    "    selector_model.fit(X_tr_resampled, y_tr_resampled)\n",
    "    selector = SelectFromModel(selector_model, threshold='mean', prefit=True)\n",
    "    selected_features = X_train.columns[selector.get_support()]\n",
    "    xgb_feature_counts[selected_features] += 1\n",
    "\n",
    "    X_tr_sel = selector.transform(X_tr_resampled)\n",
    "    X_val_sel = selector.transform(X_val)\n",
    "\n",
    "    # Train final model on selected features\n",
    "    fitted_model = xgb_model.__class__(**xgb_model.get_params())\n",
    "    fitted_model.fit(X_tr_sel, y_tr_resampled)\n",
    "    preds = fitted_model.predict(X_val_sel)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    xgb_fold_scores.append(acc)\n",
    "\n",
    "# Report Results\n",
    "xgb_mean_acc, xgb_ci = report_accuracy(xgb_fold_scores)\n",
    "\n",
    "# Feature Importance Plot for XGBoost\n",
    "final_selector_model = xgb_model.__class__(**xgb_model.get_params())\n",
    "final_selector_model.fit(X_resampled, y_resampled)\n",
    "plot_feature_importance(final_selector_model.feature_importances_, selected_features, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da48e42-1422-4260-8fe4-22f196ae5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Model Evaluation\n",
    "cb_model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "cb_fold_scores = []\n",
    "cb_feature_counts = pd.Series(0, index=X_train.columns)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train_encoded), 1):\n",
    "    print(f\"  Fold {fold}/{n_folds} - CatBoost\")\n",
    "\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_tr_resampled, y_tr_resampled = sm.fit_resample(X_tr, y_tr)\n",
    "\n",
    "    # Feature selection\n",
    "    selector_model = cb_model.__class__(**cb_model.get_params())\n",
    "    selector_model.fit(X_tr_resampled, y_tr_resampled)\n",
    "    selector = SelectFromModel(selector_model, threshold='mean', prefit=True)\n",
    "    selected_features = X_train.columns[selector.get_support()]\n",
    "    cb_feature_counts[selected_features] += 1\n",
    "\n",
    "    X_tr_sel = selector.transform(X_tr_resampled)\n",
    "    X_val_sel = selector.transform(X_val)\n",
    "\n",
    "    # Train final model on selected features\n",
    "    fitted_model = cb_model.__class__(**cb_model.get_params())\n",
    "    fitted_model.fit(X_tr_sel, y_tr_resampled)\n",
    "    preds = fitted_model.predict(X_val_sel)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    cb_fold_scores.append(acc)\n",
    "\n",
    "# Report Results\n",
    "cb_mean_acc, cb_ci = report_accuracy(cb_fold_scores)\n",
    "\n",
    "# Feature Importance Plot for CatBoost\n",
    "final_selector_model = cb_model.__class__(**cb_model.get_params())\n",
    "final_selector_model.fit(X_resampled, y_resampled)\n",
    "plot_feature_importance(final_selector_model.feature_importances_, selected_features, \"CatBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1509b-916e-4083-b58e-98f4d82f8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,)],  # Example layer sizes\n",
    "    'activation': ['relu', 'tanh'],  # Activation functions\n",
    "    'solver': ['adam', 'sgd'],  # Optimization solvers\n",
    "    'alpha': [0.0001, 0.001],  # Regularization\n",
    "    'learning_rate': ['constant', 'adaptive'],  # Learning rate schedule\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "mlp = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_mlp_model = grid_search.best_estimator_\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1b5e6-5a31-4a6e-8161-cce1bf4215d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Cross-validation accuracy\n",
    "cv_accuracy = grid_search.best_score_\n",
    "\n",
    "# Test accuracy\n",
    "y_pred = best_mlp_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"CV Accuracy: {cv_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e7898-a998-4abe-8c06-fa4f51fcb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the MLPClassifier results to the comparison table\n",
    "\n",
    "if baseline_results and hybrid_results:\n",
    "    print(\"\\n\" + \"*\"*80)\n",
    "    print(\"COMPARING BASELINE VS HYBRID VS MLPCLASSIFIER\")\n",
    "    print(\"*\"*80)\n",
    "    \n",
    "    # Add MLP results to comparison\n",
    "    mlp_results = {\n",
    "        'Model Type': 'MLPClassifier',\n",
    "        'CV Accuracy': f\"{cv_accuracy:.4f}\",\n",
    "        'Test Accuracy': f\"{test_accuracy:.4f}\",\n",
    "        'Number of Features': len(X_train.columns)\n",
    "    }\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Metric': ['Model Type', 'CV Accuracy', 'Test Accuracy', 'Number of Features'],\n",
    "        'Baseline': [\n",
    "            baseline_results['best_model'],\n",
    "            f\"{baseline_results['cv_accuracy']:.4f}\",\n",
    "            f\"{baseline_results['test_accuracy']:.4f}\",\n",
    "            len(baseline_results['best_features'])\n",
    "        ],\n",
    "        'Hybrid': [\n",
    "            hybrid_results['best_model'],\n",
    "            f\"{hybrid_results['cv_accuracy']:.4f}\",\n",
    "            f\"{hybrid_results['test_accuracy']:.4f}\",\n",
    "            len(hybrid_results['best_features'])\n",
    "        ],\n",
    "        'MLPClassifier': [\n",
    "            'MLPClassifier',\n",
    "            f\"{cv_accuracy:.4f}\",\n",
    "            f\"{test_accuracy:.4f}\",\n",
    "            len(X_train.columns)\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nComparison Summary:\")\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Calculate improvement for MLPClassifier\n",
    "    accuracy_diff_baseline = test_accuracy - baseline_results['test_accuracy']\n",
    "    accuracy_diff_hybrid = test_accuracy - hybrid_results['test_accuracy']\n",
    "    \n",
    "    print(f\"\\nAccuracy difference (MLP vs Baseline): {accuracy_diff_baseline:.4f}\")\n",
    "    print(f\"Accuracy difference (MLP vs Hybrid): {accuracy_diff_hybrid:.4f}\")\n",
    "    \n",
    "    # Plot the performance comparison\n",
    "    metrics = ['CV Accuracy', 'Test Accuracy']\n",
    "    baseline_values = [baseline_results['cv_accuracy'], baseline_results['test_accuracy']]\n",
    "    hybrid_values = [hybrid_results['cv_accuracy'], hybrid_results['test_accuracy']]\n",
    "    mlp_values = [cv_accuracy, test_accuracy]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.25  # Adjusted width for MLP comparison\n",
    "    \n",
    "    plt.bar(x - width, baseline_values, width, label='Baseline')\n",
    "    plt.bar(x, hybrid_values, width, label='Hybrid')\n",
    "    plt.bar(x + width, mlp_values, width, label='MLPClassifier')\n",
    "    \n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Performance Comparison: Baseline, Hybrid, and MLPClassifier')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.legend()\n",
    "    plt.ylim(0.95, 1.0)  # Adjust as needed\n",
    "    \n",
    "    plt.savefig('results/comparison_baseline_hybrid_mlp_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\nResults saved. Analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c67441-8be1-4c9a-8927-33a2790766e7",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e098e-00b6-4f6c-ae00-cf4450914989",
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline_results and hybrid_results:\n",
    "    print(\"\\n\" + \"*\"*80)\n",
    "    print(\"COMPARING BASELINE VS HYBRID MODELS\")\n",
    "    print(\"*\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d79e1-ea72-489c-9487-c1332c2fbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Model Type', 'CV Accuracy', 'Test Accuracy', 'Number of Features'],\n",
    "    'Baseline': [\n",
    "        baseline_results['best_model'],\n",
    "        f\"{baseline_results['cv_accuracy']:.4f}\",\n",
    "        f\"{baseline_results['test_accuracy']:.4f}\",\n",
    "        len(baseline_results['best_features'])\n",
    "    ],\n",
    "    'Hybrid': [\n",
    "        hybrid_results['best_model'],\n",
    "        f\"{hybrid_results['cv_accuracy']:.4f}\",\n",
    "        f\"{hybrid_results['test_accuracy']:.4f}\",\n",
    "        len(hybrid_results['best_features'])\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison Summary:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9f9f0-6341-465e-99d9-b232db388c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvement\n",
    "accuracy_diff = hybrid_results['test_accuracy'] - baseline_results['test_accuracy']\n",
    "percent_improvement = (accuracy_diff / baseline_results['test_accuracy']) * 100\n",
    "\n",
    "print(f\"\\nAccuracy difference: {accuracy_diff:.4f}\")\n",
    "print(f\"Percent improvement: {percent_improvement:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264dfd1-2774-40bc-bccc-404d5eb0f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accuracy_diff > 0:\n",
    "    print(\"\\nConclusion: The hybrid model (with text features) performs better than the baseline model.\")\n",
    "elif accuracy_diff < 0:\n",
    "    print(\"\\nConclusion: The baseline model performs better than the hybrid model with text features.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: Both models perform similarly. Text features did not significantly impact performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834ab40-bacf-4384-a375-43a6cb977b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-specific performance comparison\n",
    "baseline_report = pd.DataFrame(baseline_results['classification_report'])\n",
    "hybrid_report = pd.DataFrame(hybrid_results['classification_report'])\n",
    "\n",
    "print(\"\\nClass-specific Performance Comparison:\")\n",
    "for class_name in baseline_report.columns:\n",
    "    if class_name not in ['accuracy', 'macro avg', 'weighted avg']: \n",
    "        print(f\"\\n{class_name} Performance:\")\n",
    "        for metric in ['precision', 'recall', 'f1-score']:\n",
    "            baseline_val = baseline_report.loc[metric, class_name]\n",
    "            hybrid_val = hybrid_report.loc[metric, class_name]\n",
    "            diff = hybrid_val - baseline_val\n",
    "            print(f\"  {metric}: Baseline={baseline_val:.4f}, Hybrid={hybrid_val:.4f}, Diff={diff:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28e207-2409-4276-9dad-6943fc2427de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "comparison_df.to_csv('results/baseline_vs_hybrid_comparison.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff397d92-1938-4ec2-9650-3ced21e92fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison bar chart\n",
    "metrics = ['CV Accuracy', 'Test Accuracy']\n",
    "baseline_values = [baseline_results['cv_accuracy'], baseline_results['test_accuracy']]\n",
    "hybrid_values = [hybrid_results['cv_accuracy'], hybrid_results['test_accuracy']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, baseline_values, width, label='Baseline')\n",
    "plt.bar(x + width/2, hybrid_values, width, label='Hybrid (with text)')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Performance Comparison: Baseline vs Hybrid Models')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.ylim(0.95, 1.0)  # Adjust as needed to highlight differences\n",
    "\n",
    "plt.savefig('results/baseline_vs_hybrid_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6bd27-6e37-4e35-9328-df53f31d70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResults saved. Analysis complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
