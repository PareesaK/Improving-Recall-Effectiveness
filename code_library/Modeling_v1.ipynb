{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b540bd1-ceee-490e-a16b-b4d1eed54c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling notebook enhanced by https://claude.ai/\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import (classification_report, accuracy_score, \n",
    "                            confusion_matrix, ConfusionMatrixDisplay, \n",
    "                            roc_curve, auc)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe20f96-0d2e-499c-bc7a-9784fa168bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for saving results\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('results/baseline', exist_ok=True)\n",
    "os.makedirs('results/hybrid', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e63cf7-de49-429a-9ee1-fabeb87204ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22397af3-b343-424c-a3ed-eb147ccbe45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run complete modeling pipeline\n",
    "def run_model_pipeline(dataset_type='baseline'):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"MODELING PIPELINE FOR {dataset_type.upper()} DATASET\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    # Load the appropriate datasets\n",
    "    train_path = f'../data/train_{dataset_type}.csv'\n",
    "    test_path = f'../data/test_{dataset_type}.csv'\n",
    "    \n",
    "    try:\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        print(f\"Successfully loaded {dataset_type} datasets:\")\n",
    "        print(f\"Training shape: {train_df.shape}\")\n",
    "        print(f\"Testing shape: {test_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {dataset_type} dataset files. Please check file paths.\")\n",
    "        return\n",
    "    \n",
    "    # Define features and target\n",
    "    X_train = train_df.drop('Event Classification', axis=1)\n",
    "    y_train = train_df['Event Classification']\n",
    "    X_test = test_df.drop('Event Classification', axis=1)\n",
    "    y_test = test_df['Event Classification']\n",
    "    \n",
    "    # Ensure test data has same columns as train data\n",
    "    missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test[col] = 0\n",
    "    X_test = X_test[X_train.columns]\n",
    "    \n",
    "    # Encode target\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    y_test_encoded = le.transform(y_test)\n",
    "    \n",
    "    class_names = le.classes_\n",
    "    print(f\"\\nTarget Classes: {class_names}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    print(\"\\nTraining class distribution:\")\n",
    "    print(pd.Series(y_train_encoded).value_counts(normalize=True))\n",
    "    \n",
    "    # Cross-validation with different models\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Random Forest Cross-Validation\n",
    "    print(\"\\n--- Random Forest Cross-Validation ---\")\n",
    "    rf_results = cross_validate_model(\n",
    "        X_train, y_train_encoded,\n",
    "        RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        \"Random Forest\"\n",
    "    )\n",
    "    results[\"Random Forest\"] = rf_results\n",
    "    \n",
    "    # 2. XGBoost Cross-Validation\n",
    "    print(\"\\n--- XGBoost Cross-Validation ---\")\n",
    "    xgb_results = cross_validate_model(\n",
    "        X_train, y_train_encoded,\n",
    "        XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"XGBoost\"\n",
    "    )\n",
    "    results[\"XGBoost\"] = xgb_results\n",
    "    \n",
    "    # 3. CatBoost Cross-Validation\n",
    "    print(\"\\n--- CatBoost Cross-Validation ---\")\n",
    "    cat_results = cross_validate_model(\n",
    "        X_train, y_train_encoded,\n",
    "        CatBoostClassifier(verbose=0, random_state=42),\n",
    "        \"CatBoost\"\n",
    "    )\n",
    "    results[\"CatBoost\"] = cat_results\n",
    "    \n",
    "    # 4. MLP Cross-Validation\n",
    "    print(\"\\n--- MLP Cross-Validation ---\")\n",
    "    mlp_results = cross_validate_model(\n",
    "        X_train, y_train_encoded,\n",
    "        MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42),\n",
    "        \"MLPClassifier\"\n",
    "    )\n",
    "    results[\"MLPClassifier\"] = mlp_results\n",
    "    \n",
    "    # Summarize cross-validation results\n",
    "    print(\"\\n--- Cross-Validation Summary ---\")\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Model': list(results.keys()),\n",
    "        'Mean Accuracy': [r['mean_accuracy'] for r in results.values()],\n",
    "        'Std Dev': [r['std_accuracy'] for r in results.values()]\n",
    "    })\n",
    "    print(summary_df.sort_values('Mean Accuracy', ascending=False))\n",
    "    \n",
    "    # Identify best model\n",
    "    best_model_name = summary_df.sort_values('Mean Accuracy', ascending=False).iloc[0]['Model']\n",
    "    print(f\"\\nBest model based on cross-validation: {best_model_name}\")\n",
    "    \n",
    "    # Hyperparameter tuning for the best model\n",
    "    print(f\"\\n--- Hyperparameter Tuning for {best_model_name} ---\")\n",
    "    best_params, best_score = tune_hyperparameters(X_train, y_train_encoded, best_model_name)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best score: {best_score:.4f}\")\n",
    "    \n",
    "    # Train final model with best parameters\n",
    "    print(\"\\n--- Training Final Model ---\")\n",
    "    final_model = train_final_model(X_train, y_train_encoded, best_model_name, best_params)\n",
    "    \n",
    "    # Apply SMOTE for final training\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train_encoded)\n",
    "    print(f\"Original training shape: {X_train.shape}, Resampled shape: {X_train_resampled.shape}\")\n",
    "    \n",
    "    final_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\n--- Final Model Evaluation on Test Set ---\")\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    \n",
    "    # Convert encoded predictions back to original labels\n",
    "    y_pred_labels = le.inverse_transform(y_pred)\n",
    "    y_test_labels = y_test.values\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(y_test_encoded, y_pred, target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    # Save classification report to file\n",
    "    report_dict = classification_report(y_test_encoded, y_pred, target_names=class_names, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    report_df.to_csv(f'results/{dataset_type}/{best_model_name}_classification_report.csv')\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "    plt.savefig(f'results/{dataset_type}/{best_model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Normalized confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)\n",
    "    disp.plot(cmap='Blues', values_format='.2f')\n",
    "    plt.title(f'Normalized Confusion Matrix - {best_model_name}')\n",
    "    plt.savefig(f'results/{dataset_type}/{best_model_name}_normalized_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Feature importance (if applicable)\n",
    "    if best_model_name in [\"Random Forest\", \"XGBoost\", \"CatBoost\"]:\n",
    "        plot_feature_importance(final_model, X_train.columns, best_model_name, dataset_type)\n",
    "    \n",
    "    # ROC curve for multiclass\n",
    "    plot_roc_curve(final_model, X_test, y_test_encoded, class_names, best_model_name, dataset_type)\n",
    "    \n",
    "    # Return the results for later comparison\n",
    "    return {\n",
    "        'model_name': best_model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'model': final_model,\n",
    "        'report': report_dict,\n",
    "        'confusion_matrix': cm,\n",
    "        'class_names': class_names\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d9f6fb-eefb-48d8-9270-07d7e6894c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(X, y, model, model_name, n_folds=5):\n",
    "    \"\"\"Run cross-validation for a model and return performance metrics\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"Fold {fold}/{n_folds}...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train_fold, y_valid_fold = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        # Apply SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = sm.fit_resample(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        accuracy = accuracy_score(y_valid_fold, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Summarize results\n",
    "    mean_accuracy = np.mean(fold_accuracies)\n",
    "    std_accuracy = np.std(fold_accuracies)\n",
    "    \n",
    "    print(f\"\\n{model_name} - {n_folds}-Fold CV Results:\")\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})\")\n",
    "    \n",
    "    return {\n",
    "        'fold_accuracies': fold_accuracies,\n",
    "        'mean_accuracy': mean_accuracy,\n",
    "        'std_accuracy': std_accuracy\n",
    "    }\n",
    "\n",
    "def tune_hyperparameters(X, y, model_name):\n",
    "    \"\"\"Tune hyperparameters for the specified model\"\"\"\n",
    "    \n",
    "    if model_name == \"Random Forest\":\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': randint(100, 300),\n",
    "            'max_depth': randint(5, 30),\n",
    "            'min_samples_split': randint(2, 10),\n",
    "            'min_samples_leaf': randint(1, 5),\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        }\n",
    "    \n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': randint(100, 300),\n",
    "            'max_depth': randint(3, 15),\n",
    "            'learning_rate': uniform(0.01, 0.3),\n",
    "            'subsample': uniform(0.5, 0.5),\n",
    "            'colsample_bytree': uniform(0.5, 0.5)\n",
    "        }\n",
    "    \n",
    "    elif model_name == \"CatBoost\":\n",
    "        model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "        param_grid = {\n",
    "            'iterations': randint(100, 500),\n",
    "            'depth': randint(4, 10),\n",
    "            'learning_rate': uniform(0.01, 0.3),\n",
    "            'l2_leaf_reg': uniform(1, 10),\n",
    "            'border_count': randint(32, 255)\n",
    "        }\n",
    "    \n",
    "    elif model_name == \"MLPClassifier\":\n",
    "        model = MLPClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (100, 50), (50, 50, 50)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [1e-5, 1e-4, 1e-3],\n",
    "            'learning_rate': ['constant', 'adaptive'],\n",
    "            'max_iter': [300, 500]\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    # Create RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    start_time = time.time()\n",
    "    random_search.fit(X, y)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Hyperparameter tuning completed in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return random_search.best_params_, random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9bf88fd-0dad-4ba4-9d49-77d00f1465a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(X, y, model_name, best_params):\n",
    "    \"\"\"Train the final model with the best parameters\"\"\"\n",
    "    \n",
    "    if model_name == \"Random Forest\":\n",
    "        model = RandomForestClassifier(random_state=42, **best_params)\n",
    "    \n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBClassifier(eval_metric='mlogloss', random_state=42, **best_params)\n",
    "    \n",
    "    elif model_name == \"CatBoost\":\n",
    "        model = CatBoostClassifier(verbose=0, random_state=42, **best_params)\n",
    "    \n",
    "    elif model_name == \"MLPClassifier\":\n",
    "        model = MLPClassifier(random_state=42, **best_params)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13b4f2c-3111-469c-84a9-4d63d7cf4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names, model_name, dataset_type):\n",
    "    \"\"\"Plot feature importances for tree-based models\"\"\"\n",
    "    \n",
    "    if model_name == \"Random Forest\":\n",
    "        importances = model.feature_importances_\n",
    "    elif model_name == \"XGBoost\":\n",
    "        importances = model.feature_importances_\n",
    "    elif model_name == \"CatBoost\":\n",
    "        importances = model.get_feature_importance()\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot top 15 features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "    plt.title(f'Top 15 Feature Importances - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{dataset_type}/{model_name}_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save importance DataFrame\n",
    "    importance_df.to_csv(f'results/{dataset_type}/{model_name}_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38da35f-2699-404b-acf7-dbe6746f820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, X_test, y_test, class_names, model_name, dataset_type):\n",
    "    \"\"\"Plot ROC curves for multiclass classification\"\"\"\n",
    "    \n",
    "    # Binarize the output for ROC curve\n",
    "    n_classes = len(class_names)\n",
    "    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    try:\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        \n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Plot all ROC curves\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            plt.plot(fpr[i], tpr[i], lw=2,\n",
    "                    label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curves - {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f'results/{dataset_type}/{model_name}_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    except (AttributeError, ValueError) as e:\n",
    "        print(f\"Could not generate ROC curve: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e584e76-bb91-44d9-bb9a-42f10cd44cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODELING PIPELINE FOR BASELINE DATASET\n",
      "==================================================\n",
      "\n",
      "Successfully loaded baseline datasets:\n",
      "Training shape: (76065, 30)\n",
      "Testing shape: (19017, 30)\n",
      "\n",
      "Target Classes: ['Class I' 'Class II' 'Class III']\n",
      "\n",
      "Training class distribution:\n",
      "1    0.708065\n",
      "0    0.211516\n",
      "2    0.080418\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Random Forest Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9919\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9914\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9923\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9906\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9924\n",
      "\n",
      "Random Forest - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9917 (±0.0007)\n",
      "\n",
      "--- XGBoost Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9911\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9899\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9909\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9894\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9910\n",
      "\n",
      "XGBoost - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9905 (±0.0007)\n",
      "\n",
      "--- CatBoost Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9907\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9891\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9899\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9889\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9903\n",
      "\n",
      "CatBoost - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9898 (±0.0007)\n",
      "\n",
      "--- MLP Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9895\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9850\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9875\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9871\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9887\n",
      "\n",
      "MLPClassifier - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9876 (±0.0015)\n",
      "\n",
      "--- Cross-Validation Summary ---\n",
      "           Model  Mean Accuracy   Std Dev\n",
      "0  Random Forest       0.991718  0.000660\n",
      "1        XGBoost       0.990456  0.000691\n",
      "2       CatBoost       0.989759  0.000679\n",
      "3  MLPClassifier       0.987550  0.001532\n",
      "\n",
      "Best model based on cross-validation: Random Forest\n",
      "\n",
      "--- Hyperparameter Tuning for Random Forest ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Hyperparameter tuning completed in 96.28 seconds\n",
      "Best parameters: {'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 158}\n",
      "Best score: 0.9906\n",
      "\n",
      "--- Training Final Model ---\n",
      "Original training shape: (76065, 29), Resampled shape: (161577, 29)\n",
      "\n",
      "--- Final Model Evaluation on Test Set ---\n",
      "Test Accuracy: 0.9899\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      4022\n",
      "    Class II       1.00      0.99      0.99     13466\n",
      "   Class III       0.92      1.00      0.96      1529\n",
      "\n",
      "    accuracy                           0.99     19017\n",
      "   macro avg       0.97      0.99      0.98     19017\n",
      "weighted avg       0.99      0.99      0.99     19017\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the modeling pipeline for baseline dataset\n",
    "baseline_results = run_model_pipeline('baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d16c92-915d-4313-bd21-c2a4f60616c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODELING PIPELINE FOR HYBRID DATASET\n",
      "==================================================\n",
      "\n",
      "Successfully loaded hybrid datasets:\n",
      "Training shape: (76065, 330)\n",
      "Testing shape: (19017, 330)\n",
      "\n",
      "Target Classes: ['Class I' 'Class II' 'Class III']\n",
      "\n",
      "Training class distribution:\n",
      "1    0.708065\n",
      "0    0.211516\n",
      "2    0.080418\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Random Forest Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9918\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9908\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9917\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9911\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9918\n",
      "\n",
      "Random Forest - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9914 (±0.0004)\n",
      "\n",
      "--- XGBoost Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9930\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9909\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9924\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9913\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9930\n",
      "\n",
      "XGBoost - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9922 (±0.0009)\n",
      "\n",
      "--- CatBoost Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9927\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9899\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9913\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9909\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9922\n",
      "\n",
      "CatBoost - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9914 (±0.0010)\n",
      "\n",
      "--- MLP Cross-Validation ---\n",
      "Fold 1/5...\n",
      "  Accuracy: 0.9928\n",
      "Fold 2/5...\n",
      "  Accuracy: 0.9920\n",
      "Fold 3/5...\n",
      "  Accuracy: 0.9936\n",
      "Fold 4/5...\n",
      "  Accuracy: 0.9929\n",
      "Fold 5/5...\n",
      "  Accuracy: 0.9934\n",
      "\n",
      "MLPClassifier - 5-Fold CV Results:\n",
      "Mean Accuracy: 0.9930 (±0.0005)\n",
      "\n",
      "--- Cross-Validation Summary ---\n",
      "           Model  Mean Accuracy   Std Dev\n",
      "3  MLPClassifier       0.992953  0.000539\n",
      "1        XGBoost       0.992151  0.000874\n",
      "0  Random Forest       0.991442  0.000433\n",
      "2       CatBoost       0.991402  0.001002\n",
      "\n",
      "Best model based on cross-validation: MLPClassifier\n",
      "\n",
      "--- Hyperparameter Tuning for MLPClassifier ---\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Hyperparameter tuning completed in 1884.94 seconds\n",
      "Best parameters: {'solver': 'adam', 'max_iter': 500, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Best score: 0.9937\n",
      "\n",
      "--- Training Final Model ---\n",
      "Original training shape: (76065, 329), Resampled shape: (161577, 329)\n",
      "\n",
      "--- Final Model Evaluation on Test Set ---\n",
      "Test Accuracy: 0.9924\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class I       1.00      0.99      0.99      4022\n",
      "    Class II       1.00      0.99      0.99     13466\n",
      "   Class III       0.96      0.98      0.97      1529\n",
      "\n",
      "    accuracy                           0.99     19017\n",
      "   macro avg       0.98      0.99      0.99     19017\n",
      "weighted avg       0.99      0.99      0.99     19017\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the modeling pipeline for hybrid dataset\n",
    "hybrid_results = run_model_pipeline('hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfefb3b-fa15-47d3-9609-eb396c3de92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "BASELINE VS HYBRID MODEL COMPARISON\n",
      "==================================================\n",
      "    Dataset     Best Model  Accuracy\n",
      "0  Baseline  Random Forest  0.989851\n",
      "1    Hybrid  MLPClassifier  0.992428\n",
      "\n",
      "The Hybrid approach performs better with an improvement of 0.26% in accuracy.\n",
      "\n",
      "Detailed Performance Comparison:\n",
      "                     Baseline    Hybrid  Difference\n",
      "Class I precision    0.999245  0.996747   -0.002498\n",
      "Class I recall       0.986574  0.990303    0.003729\n",
      "Class I f1-score     0.992869  0.993515    0.000646\n",
      "Class II precision   0.996263  0.995316   -0.000946\n",
      "Class II recall      0.989752  0.994208    0.004456\n",
      "Class II f1-score    0.992997  0.994762    0.001765\n",
      "Class III precision  0.916067  0.956688    0.040621\n",
      "Class III recall     0.999346  0.982341   -0.017005\n",
      "Class III f1-score   0.955896  0.969345    0.013449\n",
      "Overall accuracy     0.989851  0.992428    0.002577\n",
      "\n",
      "Analysis completed. Results saved to the 'results' directory.\n"
     ]
    }
   ],
   "source": [
    "# Compare baseline vs hybrid results\n",
    "if baseline_results and hybrid_results:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"BASELINE VS HYBRID MODEL COMPARISON\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Dataset': ['Baseline', 'Hybrid'],\n",
    "        'Best Model': [baseline_results['model_name'], hybrid_results['model_name']],\n",
    "        'Accuracy': [baseline_results['accuracy'], hybrid_results['accuracy']]\n",
    "    })\n",
    "    \n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Create comparison bar chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x='Dataset', y='Accuracy', data=comparison_df)\n",
    "    plt.title('Baseline vs Hybrid Model Performance')\n",
    "    plt.ylim(0.8, 1.0)  # Set y-axis to focus on the high accuracy range\n",
    "    plt.savefig('results/baseline_vs_hybrid_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save comparison results\n",
    "    comparison_df.to_csv('results/baseline_vs_hybrid_comparison.csv', index=False)\n",
    "    \n",
    "    # Determine which approach is better\n",
    "    better_model = 'Hybrid' if hybrid_results['accuracy'] > baseline_results['accuracy'] else 'Baseline'\n",
    "    improvement = abs(hybrid_results['accuracy'] - baseline_results['accuracy']) * 100\n",
    "    \n",
    "    print(f\"\\nThe {better_model} approach performs better with an improvement of {improvement:.2f}% in accuracy.\")\n",
    "    \n",
    "    # Create detailed performance comparison\n",
    "    # Extract precision, recall, f1-score for each class\n",
    "    baseline_metrics = pd.DataFrame(baseline_results['report']).T\n",
    "    hybrid_metrics = pd.DataFrame(hybrid_results['report']).T\n",
    "    \n",
    "    # Create detailed comparison DataFrame\n",
    "    detailed_comparison = pd.DataFrame()\n",
    "    \n",
    "    for class_name in baseline_results['class_names']:\n",
    "        for metric in ['precision', 'recall', 'f1-score']:\n",
    "            baseline_value = baseline_metrics.loc[class_name, metric]\n",
    "            hybrid_value = hybrid_metrics.loc[class_name, metric]\n",
    "            \n",
    "            detailed_comparison.loc[f\"{class_name} {metric}\", 'Baseline'] = baseline_value\n",
    "            detailed_comparison.loc[f\"{class_name} {metric}\", 'Hybrid'] = hybrid_value\n",
    "            detailed_comparison.loc[f\"{class_name} {metric}\", 'Difference'] = hybrid_value - baseline_value\n",
    "    \n",
    "    # Add overall metrics\n",
    "    detailed_comparison.loc['Overall accuracy', 'Baseline'] = baseline_results['accuracy']\n",
    "    detailed_comparison.loc['Overall accuracy', 'Hybrid'] = hybrid_results['accuracy']\n",
    "    detailed_comparison.loc['Overall accuracy', 'Difference'] = hybrid_results['accuracy'] - baseline_results['accuracy']\n",
    "    \n",
    "    print(\"\\nDetailed Performance Comparison:\")\n",
    "    print(detailed_comparison)\n",
    "    \n",
    "    # Save detailed comparison\n",
    "    detailed_comparison.to_csv('results/detailed_performance_comparison.csv')\n",
    "    \n",
    "    print(\"\\nAnalysis completed. Results saved to the 'results' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
